{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzFG0X778vd8"
      },
      "source": [
        "# Análisis de Wavelets para Datos MI-EEG\n",
        "\n",
        "Este notebook implementa análisis avanzado de wavelets para extraer características temporales y espectrales de los datos EEG de imaginación motora.\n",
        "\n",
        "## Objetivos\n",
        "\n",
        "1. **Transformada Wavelet Continua (CWT)**: Análisis tiempo-frecuencia usando wavelet de Morlet\n",
        "2. **Transformada Wavelet Discreta (DWT)**: Descomposición multiresolución usando Daubechies 4\n",
        "3. **Extracción de características**: Energía por banda, frecuencia dominante, entropía espectral\n",
        "4. **Preparación para BoF**: Características optimizadas para Bag of Features\n",
        "\n",
        "## Pipeline\n",
        "\n",
        "- Carga y procesamiento de datos EEG (independiente del EDA)\n",
        "- Análisis CWT con escalas logarítmicas\n",
        "- Análisis DWT con múltiples niveles\n",
        "- Extracción de características estadísticas\n",
        "- Visualizaciones tiempo-frecuencia\n",
        "- Guardado de características para BoF\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j17H_zSa8y7j",
        "outputId": "eb069985-669f-4f63-b439-ab101831dd08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Directorio raíz: /Users/manueljurado/Downloads/datos_BCI\n",
            "✅ Directorios configurados:\n",
            "   - Datos Left: /Users/manueljurado/Downloads/datos_BCI/left_imag\n",
            "   - Datos Right: /Users/manueljurado/Downloads/datos_BCI/right_imag\n",
            "   - Wavelet Results: /Users/manueljurado/Downloads/datos_BCI/results/wavelets\n",
            "   - BoF Features: /Users/manueljurado/Downloads/datos_BCI/data/bof_features\n",
            "   - Preprocessed Data: /Users/manueljurado/Downloads/datos_BCI/data/preprocessed\n"
          ]
        }
      ],
      "source": [
        "# Instalación de dependencias (descomentar si es necesario)\n",
        "# !pip install \"numpy>=1.24.0,<2.0.0\" mne PyWavelets scikit-learn matplotlib pandas scipy tqdm joblib\n",
        "\n",
        "# Configuración para ejecución local\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Directorio raíz del proyecto (local)\n",
        "ROOT_DIR = Path.cwd()\n",
        "print(f\"Directorio raíz: {ROOT_DIR}\")\n",
        "\n",
        "# Directorios de datos\n",
        "LEFT_DIR = ROOT_DIR / 'left_imag'\n",
        "RIGHT_DIR = ROOT_DIR / 'right_imag'\n",
        "\n",
        "# Directorios de salida (estructura unificada)\n",
        "RESULTS_DIR = ROOT_DIR / 'results'\n",
        "DATA_DIR = ROOT_DIR / 'data'\n",
        "\n",
        "WAVELET_OUTPUT_DIR = RESULTS_DIR / 'wavelets'\n",
        "BOF_DATA_DIR = DATA_DIR / 'bof_features'\n",
        "PREPROCESSED_DIR = DATA_DIR / 'preprocessed'\n",
        "\n",
        "# Crear directorios si no existen\n",
        "WAVELET_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "BOF_DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
        "PREPROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"✅ Directorios configurados:\")\n",
        "print(f\"   - Datos Left: {LEFT_DIR}\")\n",
        "print(f\"   - Datos Right: {RIGHT_DIR}\")\n",
        "print(f\"   - Wavelet Results: {WAVELET_OUTPUT_DIR}\")\n",
        "print(f\"   - BoF Features: {BOF_DATA_DIR}\")\n",
        "print(f\"   - Preprocessed Data: {PREPROCESSED_DIR}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_FLdbWv8vd-",
        "outputId": "0ad55e0e-293c-4fc6-dfa5-5a341c67976b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Instalación de dependencias completada\n"
          ]
        }
      ],
      "source": [
        "# Celda de instalación de dependencias\n",
        "# Ejecutar esta celda SOLO si necesitas instalar las librerías en un entorno nuevo\n",
        "\n",
        "#%pip install mne\n",
        "#%pip install PyWavelets\n",
        "#%pip install scikit-learn\n",
        "#%pip install matplotlib\n",
        "#%pip install pandas\n",
        "#%pip install numpy\n",
        "#%pip install scipy\n",
        "#%pip install tqdm\n",
        "#%pip install joblib\n",
        "\n",
        "print(\"Instalación de dependencias completada\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIc7Q6GW8vd_",
        "outputId": "97a21d93-a788-4f66-a0e5-bd5a62bbd70f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Procesadores disponibles: 12\n",
            "Cores a utilizar: 11\n",
            "Librerías importadas correctamente\n",
            "PyWavelets versión: 1.8.0\n"
          ]
        }
      ],
      "source": [
        "# Importar librerías necesarias\n",
        "import json\n",
        "import os\n",
        "import re\n",
        "from glob import glob\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Tuple, Optional\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import mne\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pywt\n",
        "from mne.io import read_raw_eeglab\n",
        "from scipy.signal import welch\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tqdm import tqdm\n",
        "from joblib import Parallel, delayed\n",
        "import multiprocessing\n",
        "import pickle\n",
        "\n",
        "# Configurar matplotlib\n",
        "plt.rcParams['figure.figsize'] = (15, 10)\n",
        "plt.rcParams['font.size'] = 12\n",
        "plt.style.use('seaborn-v0_8')\n",
        "\n",
        "# Configuración de paralelización\n",
        "N_JOBS = max(1, multiprocessing.cpu_count() - 1)  # Usar todos los cores menos uno\n",
        "print(f\"Procesadores disponibles: {multiprocessing.cpu_count()}\")\n",
        "print(f\"Cores a utilizar: {N_JOBS}\")\n",
        "\n",
        "print(\"Librerías importadas correctamente\")\n",
        "print(f\"PyWavelets versión: {pywt.__version__}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lgghW028vd_"
      },
      "source": [
        "## Configuración de Parámetros y Carga de Datos\n",
        "\n",
        "Configuramos los parámetros necesarios y cargamos los datos EEG directamente desde los archivos originales:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wa4rS0h48veA"
      },
      "source": [
        "## Carga de Datos EEG\n",
        "\n",
        "Cargamos todos los archivos de datos de imaginación motora (left/right) y los procesamos:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q58Ew2dX8veA",
        "outputId": "cd9cf9c0-1d44-40e3-cf51-7d45a14aa709"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parámetros y funciones auxiliares definidas\n",
            "  - Bandas de frecuencia: 8.0-30.0 Hz\n",
            "  - Banda μ: 10.0-12.0 Hz\n",
            "  - Banda β: 18.0-26.0 Hz\n",
            "  - Duración por trial: 9.0 segundos\n"
          ]
        }
      ],
      "source": [
        "# Parámetros de análisis\n",
        "LOW_BAND, HIGH_BAND = 8.0, 30.0  # Rango de frecuencias de interés\n",
        "MU_BAND = (10.0, 12.0)           # Banda mu (ritmo sensoriomotor)\n",
        "BETA_BAND = (18.0, 26.0)         # Banda beta\n",
        "EXPECTED_TRIAL_SEC = 9.0         # Duración esperada de cada trial\n",
        "\n",
        "# Directorios de datos\n",
        "CANDIDATE_DIRS = {\n",
        "    \"left_imag\":  (\"left\",  \"imag\"),\n",
        "    \"right_imag\": (\"right\", \"imag\"),\n",
        "}\n",
        "\n",
        "# Regiones cerebrales por prefijos del sistema 10-20\n",
        "REGION_PREFIXES = {\n",
        "    \"F\" : (\"Fp\", \"AF\", \"F\"),    # Frontal\n",
        "    \"FC\": (\"FC\",),              # Frontocentral\n",
        "    \"C\" : (\"C\", \"Cz\"),          # Central\n",
        "    \"CP\": (\"CP\",),              # Centroparietal\n",
        "    \"P\" : (\"P\",),               # Parietal\n",
        "    \"PO\": (\"PO\",),              # Parietooccipital\n",
        "    \"O\" : (\"O\",),               # Occipital\n",
        "}\n",
        "\n",
        "# Funciones auxiliares para carga de datos\n",
        "def subject_from_fname(fname: str) -> str:\n",
        "    \"\"\"Extrae el ID del sujeto del nombre del archivo.\"\"\"\n",
        "    m = re.search(r\"(S\\d{3})\", os.path.basename(fname))\n",
        "    return m.group(1) if m else os.path.basename(fname)\n",
        "\n",
        "def try_read_epochs(fname: str) -> mne.BaseEpochs:\n",
        "    \"\"\"Lee epochs de EEGLAB, creando epochs si es necesario.\"\"\"\n",
        "    # 1) Si ya viene epocado\n",
        "    try:\n",
        "        ep = mne.read_epochs_eeglab(fname, verbose=\"ERROR\")\n",
        "        _ = ep.get_data()\n",
        "        return ep\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    # 2) Continuo -> ventaneo simple de 9s\n",
        "    raw = read_raw_eeglab(fname, preload=True, verbose=\"ERROR\")\n",
        "    try:\n",
        "        raw.filter(LOW_BAND, HIGH_BAND, verbose=\"ERROR\")\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    sfreq = float(raw.info[\"sfreq\"])\n",
        "    n_win = int(np.floor(raw.times[-1] / EXPECTED_TRIAL_SEC))\n",
        "    if n_win < 1:\n",
        "        data = np.expand_dims(raw.get_data(), axis=0)\n",
        "        return mne.EpochsArray(data, raw.info, tmin=0.0, verbose=\"ERROR\")\n",
        "\n",
        "    picks = mne.pick_types(raw.info, eeg=True, meg=False, stim=False, eog=False)\n",
        "    samps = int(EXPECTED_TRIAL_SEC * sfreq)\n",
        "    data_list: List[np.ndarray] = []\n",
        "\n",
        "    for i in range(n_win):\n",
        "        s, e = i * samps, (i + 1) * samps\n",
        "        if e <= raw.n_times:\n",
        "            data_list.append(np.expand_dims(raw.get_data(picks=picks)[:, s:e], axis=0))\n",
        "\n",
        "    data = np.concatenate(data_list, axis=0)\n",
        "    info = mne.create_info([raw.ch_names[p] for p in picks], sfreq, ch_types=\"eeg\")\n",
        "    return mne.EpochsArray(data, info, tmin=0.0, verbose=\"ERROR\")\n",
        "\n",
        "print(\"Parámetros y funciones auxiliares definidas\")\n",
        "print(f\"  - Bandas de frecuencia: {LOW_BAND}-{HIGH_BAND} Hz\")\n",
        "print(f\"  - Banda μ: {MU_BAND[0]}-{MU_BAND[1]} Hz\")\n",
        "print(f\"  - Banda β: {BETA_BAND[0]}-{BETA_BAND[1]} Hz\")\n",
        "print(f\"  - Duración por trial: {EXPECTED_TRIAL_SEC} segundos\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIOnRk538veA",
        "outputId": "fbdd71fc-cef9-4735-a353-077e2e7a551e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cargando datos de imaginación motora...\n",
            "  - Left dir: /Users/manueljurado/Downloads/datos_BCI/left_imag\n",
            "  - Right dir: /Users/manueljurado/Downloads/datos_BCI/right_imag\n",
            "\n",
            "Procesando directorio: left_imag\n",
            "  S001: 22 trials\n",
            "  S002: 22 trials\n",
            "  S003: 23 trials\n",
            "  S004: 23 trials\n",
            "  S005: 21 trials\n",
            "  S006: 23 trials\n",
            "  S007: 22 trials\n",
            "  S008: 22 trials\n",
            "  S009: 23 trials\n",
            "  S010: 23 trials\n",
            "  S011: 23 trials\n",
            "  S012: 21 trials\n",
            "  S013: 22 trials\n",
            "  S014: 22 trials\n",
            "  S015: 22 trials\n",
            "  S016: 21 trials\n",
            "  S017: 22 trials\n",
            "  S018: 21 trials\n",
            "  S019: 22 trials\n",
            "  S020: 22 trials\n",
            "\n",
            "Procesando directorio: right_imag\n",
            "  S001: 22 trials\n",
            "  S002: 22 trials\n",
            "  S003: 21 trials\n",
            "  S004: 21 trials\n",
            "  S005: 23 trials\n",
            "  S006: 21 trials\n",
            "  S007: 22 trials\n",
            "  S008: 22 trials\n",
            "  S009: 21 trials\n",
            "  S010: 21 trials\n",
            "  S011: 21 trials\n",
            "  S012: 23 trials\n",
            "  S013: 22 trials\n",
            "  S014: 22 trials\n",
            "  S015: 22 trials\n",
            "  S016: 23 trials\n",
            "  S017: 22 trials\n",
            "  S018: 23 trials\n",
            "  S019: 22 trials\n",
            "  S020: 22 trials\n",
            "\n",
            "Resumen de carga:\n",
            "  - Archivos procesados: 40\n",
            "  - Total de epochs: 40\n",
            "✅ Datos cargados correctamente\n"
          ]
        }
      ],
      "source": [
        "# Cargar epochs de imaginación (left/right) - VERSIÓN LOCAL\n",
        "epochs_list: List[mne.BaseEpochs] = []\n",
        "subjects_info = []\n",
        "\n",
        "# Usar variables definidas en celda 1\n",
        "print(f\"Cargando datos de imaginación motora...\")\n",
        "print(f\"  - Left dir: {LEFT_DIR}\")\n",
        "print(f\"  - Right dir: {RIGHT_DIR}\")\n",
        "\n",
        "for dirname, task_name in [(\"left_imag\", \"left\"), (\"right_imag\", \"right\")]:\n",
        "    dpath = Path.cwd() / dirname\n",
        "    if not dpath.is_dir():\n",
        "        print(f\"⚠️  Advertencia: No existe {dpath}, omitiendo...\")\n",
        "        continue\n",
        "\n",
        "    print(f\"\\nProcesando directorio: {dirname}\")\n",
        "    files_processed = 0\n",
        "\n",
        "    for set_path in sorted(glob(str(dpath / \"*.set\"))):\n",
        "        try:\n",
        "            subject_id = subject_from_fname(set_path)\n",
        "            ep = try_read_epochs(set_path)\n",
        "            epochs_list.append(ep)\n",
        "            subjects_info.append({\n",
        "                'subject': subject_id,\n",
        "                'task': task_name,\n",
        "                'file': str(set_path),\n",
        "                'n_trials': ep.get_data().shape[0]\n",
        "            })\n",
        "            files_processed += 1\n",
        "            print(f\"  {subject_id}: {ep.get_data().shape[0]} trials\")\n",
        "        except Exception as e:\n",
        "            print(f\"  ⚠️  Error en {set_path}: {e}\")\n",
        "\n",
        "print(f\"\\nResumen de carga:\")\n",
        "print(f\"  - Archivos procesados: {len(subjects_info)}\")\n",
        "print(f\"  - Total de epochs: {len(epochs_list)}\")\n",
        "\n",
        "if not epochs_list:\n",
        "    raise ValueError(\"❌ Error: No se cargaron epochs. Verificar archivos de datos.\")\n",
        "else:\n",
        "    print(\"✅ Datos cargados correctamente\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTb613ih8veB",
        "outputId": "8c9c79a0-515c-45ba-c1f3-75cc8be118fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Configuración de directorios:\n",
            "  - Directorio de datos: /Users/manueljurado/Downloads/datos_BCI\n",
            "  - Directorio de salida wavelets: /Users/manueljurado/Downloads/datos_BCI/results/wavelets\n"
          ]
        }
      ],
      "source": [
        "# Configuración de directorios (usar variables ya definidas en celda 1)\n",
        "data_root = Path(\".\").resolve()\n",
        "output_dir = WAVELET_OUTPUT_DIR  # Usar variable global\n",
        "wavelet_output_dir = WAVELET_OUTPUT_DIR  # Usar variable global\n",
        "\n",
        "print(f\"\\nConfiguración de directorios:\")\n",
        "print(f\"  - Directorio de datos: {data_root}\")\n",
        "print(f\"  - Directorio de salida wavelets: {wavelet_output_dir.resolve()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7w1HlUBX8veB"
      },
      "source": [
        "## Carga de Datos EEG\n",
        "\n",
        "Cargamos todos los archivos de datos de imaginación motora (left/right) y los procesamos:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WQHNqz48veB"
      },
      "source": [
        "## Preparación de Datos\n",
        "\n",
        "Concatenamos todos los epochs y preparamos los datos para el análisis de wavelets:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7eiZ4cDA8veB",
        "outputId": "ecf63c61-5cfe-4ade-85b6-56fa1988091f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Información de los datos:\n",
            "  - Canales: 64\n",
            "  - Frecuencia de muestreo: 128.0 Hz\n",
            "  - Primeros 10 canales: ['FC5', 'FC3', 'FC1', 'FCZ', 'FC2', 'FC4', 'FC6', 'C5', 'C3', 'C1']\n",
            "\n",
            "Datos concatenados:\n",
            "  - Trials totales: 880\n",
            "  - Canales: 64\n",
            "  - Muestras por trial: 1152\n",
            "  - Duración por trial: 9.0 segundos\n",
            "\n",
            "Regiones identificadas: ['F', 'FC', 'C', 'CP', 'P', 'PO', 'O']\n",
            "  - Región F: 26 canales\n",
            "  - Región FC: 7 canales\n",
            "  - Región C: 14 canales\n",
            "  - Región CP: 7 canales\n",
            "  - Región P: 14 canales\n",
            "  - Región PO: 5 canales\n",
            "  - Región O: 3 canales\n"
          ]
        }
      ],
      "source": [
        "# Concatenar epochs y verificar consistencia\n",
        "base_info = epochs_list[0].info\n",
        "ch_names = epochs_list[0].ch_names\n",
        "sfreq = float(epochs_list[0].info[\"sfreq\"])\n",
        "\n",
        "print(f\"\\nInformación de los datos:\")\n",
        "print(f\"  - Canales: {len(ch_names)}\")\n",
        "print(f\"  - Frecuencia de muestreo: {sfreq} Hz\")\n",
        "print(f\"  - Primeros 10 canales: {ch_names[:10]}\")\n",
        "\n",
        "# Verificar consistencia entre archivos\n",
        "for i, ep in enumerate(epochs_list[1:], 1):\n",
        "    if ep.ch_names != ch_names:\n",
        "        print(f\"Advertencia: Los órdenes de canales difieren en archivo {i}\")\n",
        "    if int(ep.info[\"sfreq\"]) != int(sfreq):\n",
        "        print(f\"Advertencia: sfreq inconsistente en archivo {i}\")\n",
        "\n",
        "# Concatenar todos los datos\n",
        "X = np.concatenate([ep.get_data() for ep in epochs_list], axis=0)  # (N, ch, T)\n",
        "N, C, T = X.shape\n",
        "\n",
        "print(f\"\\nDatos concatenados:\")\n",
        "print(f\"  - Trials totales: {N}\")\n",
        "print(f\"  - Canales: {C}\")\n",
        "print(f\"  - Muestras por trial: {T}\")\n",
        "print(f\"  - Duración por trial: {T/sfreq:.1f} segundos\")\n",
        "\n",
        "# Agrupar canales por regiones cerebrales\n",
        "ch_upper = [c.upper() for c in ch_names]\n",
        "region_indices: Dict[str, List[int]] = {}\n",
        "\n",
        "for reg, prefixes in REGION_PREFIXES.items():\n",
        "    idxs = []\n",
        "    for i, c in enumerate(ch_upper):\n",
        "        if any(c.startswith(p) for p in prefixes):\n",
        "            idxs.append(i)\n",
        "    region_indices[reg] = idxs\n",
        "\n",
        "print(f\"\\nRegiones identificadas: {list(region_indices.keys())}\")\n",
        "for reg, idxs in region_indices.items():\n",
        "    if idxs:\n",
        "        print(f\"  - Región {reg}: {len(idxs)} canales\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ak483Y158veC"
      },
      "source": [
        "## Guardado Opcional de Datos Procesados\n",
        "\n",
        "Opcionalmente, guardamos los datos procesados para uso posterior o compatibilidad con otros notebooks:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKd76y8j8veC",
        "outputId": "8925b856-9396-42ac-d971-15444a66383e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Datos compartidos guardados en: /Users/manueljurado/Downloads/datos_BCI/data/preprocessed\n",
            "Archivos generados:\n",
            "  - X_data.npy: Datos concatenados ((880, 64, 1152))\n",
            "  - ch_names.npy: Nombres de canales (64 canales)\n",
            "  - sfreq.npy: Frecuencia de muestreo (128.0 Hz)\n",
            "  - data_dimensions.npy: Dimensiones (880, 64, 1152)\n",
            "  - subjects_info.csv: Información de sujetos\n",
            "  - region_info.json: Información de regiones\n",
            "  - config_params.json: Parámetros de configuración\n",
            "\n",
            "Datos preparados para análisis de wavelets:\n",
            "  - Datos concatenados: (880, 64, 1152) (trials, channels, time)\n",
            "  - Canales: 64\n",
            "  - Frecuencia de muestreo: 128.0 Hz\n",
            "  - Dimensiones: 880 trials, 64 canales, 1152 muestras\n",
            "  - Duración por trial: 9.0 segundos\n",
            "  - Sujetos procesados: 40\n",
            "  - Regiones identificadas: ['F', 'FC', 'C', 'CP', 'P', 'PO', 'O']\n"
          ]
        }
      ],
      "source": [
        "# Usar variable global definida en celda 1\n",
        "shared_data_dir = PREPROCESSED_DIR\n",
        "\n",
        "# Guardar datos principales\n",
        "np.save(shared_data_dir / \"X_data.npy\", X)  # Datos concatenados (trials, channels, time)\n",
        "np.save(shared_data_dir / \"ch_names.npy\", ch_names)  # Nombres de canales\n",
        "np.save(shared_data_dir / \"sfreq.npy\", np.array([sfreq]))  # Frecuencia de muestreo\n",
        "np.save(shared_data_dir / \"data_dimensions.npy\", np.array([N, C, T]))  # Dimensiones\n",
        "\n",
        "# Guardar información de sujetos\n",
        "subjects_df = pd.DataFrame(subjects_info)\n",
        "subjects_df.to_csv(shared_data_dir / \"subjects_info.csv\", index=False)\n",
        "\n",
        "# Guardar información de regiones\n",
        "region_info = {\n",
        "    'region_indices': region_indices,\n",
        "    'region_prefixes': REGION_PREFIXES\n",
        "}\n",
        "with open(shared_data_dir / \"region_info.json\", 'w') as f:\n",
        "    json.dump(region_info, f, indent=2)\n",
        "\n",
        "# Guardar parámetros de configuración\n",
        "config_params = {\n",
        "    'LOW_BAND': LOW_BAND,\n",
        "    'HIGH_BAND': HIGH_BAND,\n",
        "    'MU_BAND': list(MU_BAND),\n",
        "    'BETA_BAND': list(BETA_BAND),\n",
        "    'EXPECTED_TRIAL_SEC': EXPECTED_TRIAL_SEC,\n",
        "    'CANDIDATE_DIRS': CANDIDATE_DIRS\n",
        "}\n",
        "with open(shared_data_dir / \"config_params.json\", 'w') as f:\n",
        "    json.dump(config_params, f, indent=2)\n",
        "\n",
        "print(f\"Datos compartidos guardados en: {shared_data_dir.resolve()}\")\n",
        "print(\"Archivos generados:\")\n",
        "print(f\"  - X_data.npy: Datos concatenados ({X.shape})\")\n",
        "print(f\"  - ch_names.npy: Nombres de canales ({len(ch_names)} canales)\")\n",
        "print(f\"  - sfreq.npy: Frecuencia de muestreo ({sfreq} Hz)\")\n",
        "print(f\"  - data_dimensions.npy: Dimensiones ({N}, {C}, {T})\")\n",
        "print(f\"  - subjects_info.csv: Información de sujetos\")\n",
        "print(f\"  - region_info.json: Información de regiones\")\n",
        "print(f\"  - config_params.json: Parámetros de configuración\")\n",
        "\n",
        "print(\"\\nDatos preparados para análisis de wavelets:\")\n",
        "print(f\"  - Datos concatenados: {X.shape} (trials, channels, time)\")\n",
        "print(f\"  - Canales: {len(ch_names)}\")\n",
        "print(f\"  - Frecuencia de muestreo: {sfreq} Hz\")\n",
        "print(f\"  - Dimensiones: {N} trials, {C} canales, {T} muestras\")\n",
        "print(f\"  - Duración por trial: {T/sfreq:.1f} segundos\")\n",
        "print(f\"  - Sujetos procesados: {len(subjects_info)}\")\n",
        "print(f\"  - Regiones identificadas: {list(region_indices.keys())}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6t871sJK8veC"
      },
      "source": [
        "## Configuración de Wavelets\n",
        "\n",
        "Definimos los parámetros para el análisis de wavelets:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UqFHytAt8veC",
        "outputId": "bec45c85-3b95-4e1d-d787-8617068c30a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Configuración de wavelets:\n",
            "Escalas CWT: 50 escalas desde 3.2 hasta 316.2\n",
            "Wavelet CWT: cmor5.0-1.0 con ancho 5.0\n",
            "Wavelet DWT: db4 con 6 niveles\n",
            "Bandas de frecuencia: ['delta', 'theta', 'alpha', 'beta', 'gamma']\n"
          ]
        }
      ],
      "source": [
        "# Configurar parámetros de wavelets\n",
        "CWT_SCALES = np.logspace(0.5, 2.5, 50)  # Escalas logarítmicas (1.6-316 Hz aprox)\n",
        "CWT_WAVELET = 'cmor5.0-1.0'  # Complex Morlet wavelet para análisis tiempo-frecuencia (ancho 5.0, frecuencia central 1.0)\n",
        "CWT_WIDTH = 5.0  # Ancho de la wavelet de Morlet\n",
        "\n",
        "# Parámetros DWT\n",
        "DWT_WAVELET = 'db4'  # Wavelet Daubechies 4\n",
        "DWT_LEVELS = 6  # Niveles de descomposición\n",
        "\n",
        "# Bandas de frecuencia de interés para wavelets\n",
        "FREQ_BANDS = {\n",
        "    'delta': (1, 4),\n",
        "    'theta': (4, 8),\n",
        "    'alpha': (8, 13),\n",
        "    'beta': (13, 30),\n",
        "    'gamma': (30, 100)\n",
        "}\n",
        "\n",
        "print(\"Configuración de wavelets:\")\n",
        "print(f\"Escalas CWT: {len(CWT_SCALES)} escalas desde {CWT_SCALES[0]:.1f} hasta {CWT_SCALES[-1]:.1f}\")\n",
        "print(f\"Wavelet CWT: {CWT_WAVELET} con ancho {CWT_WIDTH}\")\n",
        "print(f\"Wavelet DWT: {DWT_WAVELET} con {DWT_LEVELS} niveles\")\n",
        "print(f\"Bandas de frecuencia: {list(FREQ_BANDS.keys())}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohn7ogBI8veD"
      },
      "source": [
        "### Funciones Auxiliares para Wavelets\n",
        "\n",
        "Definimos las funciones específicas para el análisis de wavelets:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xD6VxGnx8veD",
        "outputId": "1934d9b8-0dd2-4f34-cbec-abf822066d3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Funciones auxiliares para wavelets definidas (versión optimizada)\n",
            "PyWavelets versión: 1.8.0\n"
          ]
        }
      ],
      "source": [
        "def scales_to_frequencies(scales: np.ndarray, wavelet: str, sampling_rate: float, sort_result: bool = True) -> np.ndarray:\n",
        "    \"\"\"Convierte escalas wavelet a frecuencias.\n",
        "\n",
        "    Si sort_result=True, devuelve frecuencias ordenadas ascendentemente (útil para reporte).\n",
        "    Si sort_result=False, conserva el orden original de las escalas (útil para enmascarar).\n",
        "    \"\"\"\n",
        "    if wavelet.startswith('cmor'):\n",
        "        if '-' in wavelet:\n",
        "            bandwidth = float(wavelet.split('-')[0].replace('cmor', ''))\n",
        "        else:\n",
        "            bandwidth = CWT_WIDTH\n",
        "        frequencies = (bandwidth * sampling_rate) / (2 * np.pi * scales)\n",
        "    else:\n",
        "        frequencies = sampling_rate / (2 * scales)\n",
        "    if sort_result:\n",
        "        sorted_indices = np.argsort(frequencies)\n",
        "        return frequencies[sorted_indices]\n",
        "    return frequencies\n",
        "\n",
        "\n",
        "def _compute_single_cwt_and_extract_features(args):\n",
        "    \"\"\"Calcula CWT y extrae características para una sola señal (usa máscaras precomputadas).\"\"\"\n",
        "    signal, scales, wavelet, sampling_period, original_frequencies, band_masks = args\n",
        "\n",
        "    # Reducir memoria/tiempo: usar float32 para la señal\n",
        "    if signal.dtype != np.float32:\n",
        "        signal = signal.astype(np.float32, copy=False)\n",
        "\n",
        "    coefficients, _ = pywt.cwt(signal, scales, wavelet, sampling_period=sampling_period)\n",
        "    power_spectrum = np.abs(coefficients) ** 2  # (n_scales, n_times)\n",
        "\n",
        "    features = {}\n",
        "\n",
        "    # 1) Energía por banda\n",
        "    for band_name, mask in band_masks.items():\n",
        "        if mask is None or not mask.any():\n",
        "            features[f'cwt_energy_{band_name}'] = np.nan\n",
        "            continue\n",
        "        band_coeffs = coefficients[mask, :]\n",
        "        features[f'cwt_energy_{band_name}'] = float(np.mean(np.abs(band_coeffs) ** 2))\n",
        "\n",
        "    # 2) Frecuencia dominante\n",
        "    power_mean_time = np.mean(power_spectrum, axis=1)\n",
        "    if power_mean_time.sum() > 1e-10:\n",
        "        dominant_idx = int(np.argmax(power_mean_time))\n",
        "        features['cwt_dominant_freq'] = float(original_frequencies[dominant_idx])\n",
        "    else:\n",
        "        features['cwt_dominant_freq'] = np.nan\n",
        "\n",
        "    # 3) Entropía espectral\n",
        "    power_norm = power_mean_time / (np.sum(power_mean_time) + 1e-10)\n",
        "    power_norm = power_norm[power_norm > 0]\n",
        "    spectral_entropy = -np.sum(power_norm * np.log(power_norm + 1e-10))\n",
        "    features['cwt_spectral_entropy'] = float(spectral_entropy)\n",
        "\n",
        "    return features\n",
        "\n",
        "\n",
        "def compute_cwt_features_optimized(data: np.ndarray, sfreq: float, freq_bands: Dict[str, Tuple[float, float]],\n",
        "                                   n_jobs: int = -1, chunk_size: int = 100,\n",
        "                                   use_cache: bool = True, cache_dir: Optional[Path] = None) -> Tuple[Dict[str, np.ndarray], np.ndarray]:\n",
        "    \"\"\"Calcula coeficientes CWT y extrae características (memoria/CPU optimizado).\"\"\"\n",
        "    n_trials, n_channels, n_times = data.shape\n",
        "\n",
        "    # Frecuencias de referencia (ordenadas) para reporte\n",
        "    frequencies_report = scales_to_frequencies(CWT_SCALES, CWT_WAVELET, sfreq, sort_result=True)\n",
        "    # Frecuencias en el orden original de escalas (para enmascarar y mapeo)\n",
        "    original_frequencies = scales_to_frequencies(CWT_SCALES, CWT_WAVELET, sfreq, sort_result=False)\n",
        "\n",
        "    # Cache\n",
        "    cache_file = None\n",
        "    if use_cache:\n",
        "        if cache_dir is None:\n",
        "            cache_dir = Path(\"wavelet_reports\") / \"cwt_features_cache\"\n",
        "        cache_dir.mkdir(parents=True, exist_ok=True)\n",
        "        import hashlib\n",
        "        freq_bands_str = json.dumps(freq_bands, sort_keys=True)\n",
        "        params_hash = hashlib.md5(\n",
        "            f\"{data.shape}_{CWT_SCALES.tobytes()}_{CWT_WAVELET}_{sfreq}_{freq_bands_str}\".encode()\n",
        "        ).hexdigest()[:8]\n",
        "        cache_file = cache_dir / f\"cwt_features_{params_hash}.pkl\"\n",
        "        if cache_file.exists():\n",
        "            try:\n",
        "                with open(cache_file, 'rb') as f:\n",
        "                    cached = pickle.load(f)\n",
        "                if isinstance(cached, dict) and all(\n",
        "                    isinstance(v, np.ndarray) and v.shape == (n_trials, n_channels)\n",
        "                    for v in cached.values()\n",
        "                ):\n",
        "                    expected = [f'cwt_energy_{b}' for b in freq_bands.keys()] + ['cwt_dominant_freq', 'cwt_spectral_entropy']\n",
        "                    if all(k in cached for k in expected):\n",
        "                        print(f\"Cargando características CWT desde cache: {cache_file}\")\n",
        "                        return cached, frequencies_report\n",
        "            except Exception as e:\n",
        "                print(f\"Error al cargar cache: {e}. Recalculando...\")\n",
        "\n",
        "    # n_jobs\n",
        "    if n_jobs == -1:\n",
        "        try:\n",
        "            n_jobs = N_JOBS\n",
        "        except NameError:\n",
        "            n_jobs = max(1, multiprocessing.cpu_count() - 1)\n",
        "\n",
        "    print(\"Calculando coeficientes CWT y extrayendo características (optimizado)...\")\n",
        "    print(f\"  - Total de señales a procesar: {n_trials * n_channels}\")\n",
        "    print(f\"  - Procesadores a utilizar: {n_jobs if n_jobs > 0 else 'todos'}\")\n",
        "    print(f\"  - Chunk size: {chunk_size}\")\n",
        "\n",
        "    # Precomputar máscaras de bandas sobre frecuencias en orden original\n",
        "    band_masks: Dict[str, Optional[np.ndarray]] = {}\n",
        "    for band_name, (fmin, fmax) in freq_bands.items():\n",
        "        mask = (original_frequencies >= fmin) & (original_frequencies <= fmax)\n",
        "        band_masks[band_name] = mask if mask.any() else None\n",
        "\n",
        "    # Preparar argumentos\n",
        "    data_flat = data.reshape(n_trials * n_channels, n_times)\n",
        "    args_list = [\n",
        "        (data_flat[i, :], CWT_SCALES, CWT_WAVELET, 1.0 / sfreq, original_frequencies, band_masks)\n",
        "        for i in range(n_trials * n_channels)\n",
        "    ]\n",
        "\n",
        "    results = Parallel(n_jobs=n_jobs, backend='threading', batch_size=chunk_size)(\n",
        "        delayed(_compute_single_cwt_and_extract_features)(args)\n",
        "        for args in tqdm(args_list, desc=\"Procesando CWT y extrayendo características\")\n",
        "    )\n",
        "\n",
        "    # Ensamblar resultados sin DataFrame\n",
        "    feature_lists: Dict[str, List[float]] = {}\n",
        "    for res in results:\n",
        "        for k, v in res.items():\n",
        "            feature_lists.setdefault(k, []).append(v)\n",
        "\n",
        "    extracted_features: Dict[str, np.ndarray] = {}\n",
        "    for k, vals in feature_lists.items():\n",
        "        extracted_features[k] = np.asarray(vals, dtype=np.float32).reshape(n_trials, n_channels)\n",
        "\n",
        "    if use_cache and cache_file is not None:\n",
        "        try:\n",
        "            with open(cache_file, 'wb') as f:\n",
        "                pickle.dump(extracted_features, f)\n",
        "            print(f\"Características CWT guardadas en cache: {cache_file}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error al guardar cache: {e}\")\n",
        "\n",
        "    return extracted_features, frequencies_report\n",
        "\n",
        "\n",
        "print(\"Funciones auxiliares para wavelets definidas (versión optimizada)\")\n",
        "print(f\"PyWavelets versión: {pywt.__version__}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euliYbEA8veD"
      },
      "source": [
        "## Análisis CWT (Transformada Wavelet Continua)\n",
        "\n",
        "Calculamos los coeficientes CWT para análisis tiempo-frecuencia:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HH3KDDtR8veE",
        "outputId": "6e3833a5-0779-406f-948d-ddcf2d5874cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iniciando análisis CWT y extracción de características optimizada...\n",
            "Datos de entrada: (880, 64, 1152) (trials, channels, time)\n",
            "Frecuencia de muestreo: 128.0 Hz\n",
            "Bandas de frecuencia para extracción: ['delta', 'theta', 'alpha', 'beta', 'gamma']\n",
            "Calculando coeficientes CWT y extrayendo características (optimizado)...\n",
            "  - Total de señales a procesar: 56320\n",
            "  - Procesadores a utilizar: 11\n",
            "  - Chunk size: 50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Procesando CWT y extrayendo características: 100%|██████████| 56320/56320 [06:45<00:00, 138.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Características CWT guardadas en cache: wavelet_reports/cwt_features_cache/cwt_features_d19cc8dc.pkl\n",
            "\n",
            "Análisis CWT y extracción de características completados:\n",
            "Características CWT extraídas:\n",
            "  - cwt_energy_delta: (880, 64)\n",
            "  - cwt_energy_theta: (880, 64)\n",
            "  - cwt_energy_alpha: (880, 64)\n",
            "  - cwt_energy_beta: (880, 64)\n",
            "  - cwt_energy_gamma: (880, 64)\n",
            "  - cwt_dominant_freq: (880, 64)\n",
            "  - cwt_spectral_entropy: (880, 64)\n",
            "Frecuencias CWT: 50 puntos\n",
            "Rango de frecuencias: 0.3 - 32.2 Hz\n",
            "\n",
            "Bandas de frecuencia CWT (basado en escalas y sfreq):\n",
            "  - delta (1-4 Hz): 14 escalas\n",
            "  - theta (4-8 Hz): 8 escalas\n",
            "  - alpha (8-13 Hz): 5 escalas\n",
            "  - beta (13-30 Hz): 9 escalas\n",
            "  - gamma (30-100 Hz): 1 escalas\n"
          ]
        }
      ],
      "source": [
        "# Calcular coeficientes CWT y extraer características usando la función optimizada\n",
        "print(\"Iniciando análisis CWT y extracción de características optimizada...\")\n",
        "print(f\"Datos de entrada: {X.shape} (trials, channels, time)\")\n",
        "print(f\"Frecuencia de muestreo: {sfreq} Hz\")\n",
        "print(f\"Bandas de frecuencia para extracción: {list(FREQ_BANDS.keys())}\")\n",
        "\n",
        "\n",
        "# Las características CWT más importantes para BoF se extraen directamente aquí\n",
        "# Definimos las características clave que queremos obtener de CWT para el paso de combinación\n",
        "cwt_key_features_to_extract = {\n",
        "    'cwt_energy_delta': FREQ_BANDS['delta'],\n",
        "    'cwt_energy_theta': FREQ_BANDS['theta'],\n",
        "    'cwt_energy_alpha': FREQ_BANDS['alpha'],\n",
        "    'cwt_energy_beta': FREQ_BANDS['beta'],\n",
        "    'cwt_energy_gamma': FREQ_BANDS['gamma'],\n",
        "    # Frecuencia dominante y entropía espectral se extraen si es posible\n",
        "    # No necesitan una banda de frecuencia específica, se calculan sobre todas las escalas\n",
        "}\n",
        "\n",
        "\n",
        "cwt_features, cwt_frequencies = compute_cwt_features_optimized(\n",
        "    X, sfreq,\n",
        "    freq_bands=FREQ_BANDS, # Pasar las bandas de frecuencia para extracción\n",
        "    n_jobs=-1,           # Usar procesamiento paralelo (-1 = N_JOBS global)\n",
        "    chunk_size=50,       # Procesar 50 señales por lote\n",
        "    use_cache=True       # Habilitar cache\n",
        ")\n",
        "\n",
        "print(f\"\\nAnálisis CWT y extracción de características completados:\")\n",
        "print(f\"Características CWT extraídas:\")\n",
        "for feature_name, feature_array in cwt_features.items():\n",
        "    print(f\"  - {feature_name}: {feature_array.shape}\")\n",
        "\n",
        "print(f\"Frecuencias CWT: {len(cwt_frequencies)} puntos\")\n",
        "print(f\"Rango de frecuencias: {cwt_frequencies[0]:.1f} - {cwt_frequencies[-1]:.1f} Hz\")\n",
        "\n",
        "\n",
        "# Mostrar información sobre las bandas de frecuencia (basado en las frecuencias calculadas)\n",
        "print(f\"\\nBandas de frecuencia CWT (basado en escalas y sfreq):\")\n",
        "for band_name, (fmin, fmax) in FREQ_BANDS.items():\n",
        "    # Usar cwt_frequencies que ya está ordenado\n",
        "    mask = (cwt_frequencies >= fmin) & (cwt_frequencies <= fmax)\n",
        "    n_scales = mask.sum()\n",
        "    if n_scales > 0:\n",
        "        print(f\"  - {band_name} ({fmin}-{fmax} Hz): {n_scales} escalas\")\n",
        "    else:\n",
        "        print(f\"  - {band_name} ({fmin}-{fmax} Hz): fuera del rango\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HfL0J-178veF"
      },
      "source": [
        "## Análisis DWT (Transformada Wavelet Discreta)\n",
        "\n",
        "Implementamos análisis DWT para descomposición multiresolución:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-UtpIji8veF",
        "outputId": "463daeb7-fe3f-4394-8833-97314f3c724b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iniciando análisis DWT...\n",
            "Datos de entrada: (880, 64, 1152) (trials, channels, time)\n",
            "Wavelet: db4, Niveles: 6\n",
            "Calculando coeficientes DWT...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Trials: 100%|██████████| 880/880 [00:06<00:00, 145.14it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "DWT completado:\n",
            "Coeficientes DWT por nivel:\n",
            "  - level_0: (880, 64, 24)\n",
            "  - level_1: (880, 64, 24)\n",
            "  - level_2: (880, 64, 42)\n",
            "  - level_3: (880, 64, 78)\n",
            "  - level_4: (880, 64, 150)\n",
            "  - level_5: (880, 64, 293)\n",
            "  - level_6: (880, 64, 579)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "def compute_dwt_coefficients(data: np.ndarray, wavelet: str, levels: int) -> Dict[str, np.ndarray]:\n",
        "    \"\"\"\n",
        "    Calcula coeficientes DWT para todos los canales y trials.\n",
        "\n",
        "    Args:\n",
        "        data: Array de forma (trials, channels, time)\n",
        "        wavelet: Tipo de wavelet (ej. 'db4')\n",
        "        levels: Número de niveles de descomposición\n",
        "\n",
        "    Returns:\n",
        "        Diccionario con coeficientes DWT por nivel\n",
        "    \"\"\"\n",
        "    n_trials, n_channels, n_times = data.shape\n",
        "\n",
        "    # Inicializar diccionario para coeficientes\n",
        "    dwt_coeffs = {}\n",
        "\n",
        "    print(\"Calculando coeficientes DWT...\")\n",
        "    for trial_idx in tqdm(range(n_trials), desc=\"Trials\"):\n",
        "        for ch_idx in range(n_channels):\n",
        "            signal = data[trial_idx, ch_idx, :]\n",
        "\n",
        "            # Calcular DWT\n",
        "            coeffs = pywt.wavedec(signal, wavelet, level=levels)\n",
        "\n",
        "            # Guardar coeficientes por nivel\n",
        "            for level, coeff in enumerate(coeffs):\n",
        "                key = f'level_{level}'\n",
        "                if key not in dwt_coeffs:\n",
        "                    dwt_coeffs[key] = np.zeros((n_trials, n_channels, len(coeff)))\n",
        "                dwt_coeffs[key][trial_idx, ch_idx, :] = coeff\n",
        "\n",
        "    return dwt_coeffs\n",
        "\n",
        "# Calcular coeficientes DWT\n",
        "print(\"Iniciando análisis DWT...\")\n",
        "print(f\"Datos de entrada: {X.shape} (trials, channels, time)\")\n",
        "print(f\"Wavelet: {DWT_WAVELET}, Niveles: {DWT_LEVELS}\")\n",
        "\n",
        "dwt_coeffs = compute_dwt_coefficients(X, DWT_WAVELET, DWT_LEVELS)\n",
        "\n",
        "print(f\"\\nDWT completado:\")\n",
        "print(f\"Coeficientes DWT por nivel:\")\n",
        "for level_key, coeff_array in dwt_coeffs.items():\n",
        "    print(f\"  - {level_key}: {coeff_array.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_iaRC2l8veF"
      },
      "source": [
        "### Extracción de Características DWT\n",
        "\n",
        "Extraemos características estadísticas de los coeficientes DWT:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJeymvH18veF",
        "outputId": "2b3cda91-1731-43ec-d08d-9c52f259c099"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extrayendo características DWT...\n",
            "  - Energía level_0: (880, 64)\n",
            "  - Energía level_1: (880, 64)\n",
            "  - Energía level_2: (880, 64)\n",
            "  - Energía level_3: (880, 64)\n",
            "  - Energía level_4: (880, 64)\n",
            "  - Energía level_5: (880, 64)\n",
            "  - Energía level_6: (880, 64)\n",
            "  - Estadísticas level_0: media, std, max\n",
            "  - Estadísticas level_1: media, std, max\n",
            "  - Estadísticas level_2: media, std, max\n",
            "  - Estadísticas level_3: media, std, max\n",
            "  - Estadísticas level_4: media, std, max\n",
            "  - Estadísticas level_5: media, std, max\n",
            "  - Estadísticas level_6: media, std, max\n",
            "  - Relación de energía level0/level1: (880, 64)\n",
            "\n",
            "Características DWT extraídas:\n",
            "  - dwt_energy_level_0: (880, 64)\n",
            "  - dwt_energy_level_1: (880, 64)\n",
            "  - dwt_energy_level_2: (880, 64)\n",
            "  - dwt_energy_level_3: (880, 64)\n",
            "  - dwt_energy_level_4: (880, 64)\n",
            "  - dwt_energy_level_5: (880, 64)\n",
            "  - dwt_energy_level_6: (880, 64)\n",
            "  - dwt_mean_level_0: (880, 64)\n",
            "  - dwt_std_level_0: (880, 64)\n",
            "  - dwt_max_level_0: (880, 64)\n",
            "  - dwt_mean_level_1: (880, 64)\n",
            "  - dwt_std_level_1: (880, 64)\n",
            "  - dwt_max_level_1: (880, 64)\n",
            "  - dwt_mean_level_2: (880, 64)\n",
            "  - dwt_std_level_2: (880, 64)\n",
            "  - dwt_max_level_2: (880, 64)\n",
            "  - dwt_mean_level_3: (880, 64)\n",
            "  - dwt_std_level_3: (880, 64)\n",
            "  - dwt_max_level_3: (880, 64)\n",
            "  - dwt_mean_level_4: (880, 64)\n",
            "  - dwt_std_level_4: (880, 64)\n",
            "  - dwt_max_level_4: (880, 64)\n",
            "  - dwt_mean_level_5: (880, 64)\n",
            "  - dwt_std_level_5: (880, 64)\n",
            "  - dwt_max_level_5: (880, 64)\n",
            "  - dwt_mean_level_6: (880, 64)\n",
            "  - dwt_std_level_6: (880, 64)\n",
            "  - dwt_max_level_6: (880, 64)\n",
            "  - dwt_energy_ratio_level0_level1: (880, 64)\n"
          ]
        }
      ],
      "source": [
        "def extract_dwt_features(dwt_coeffs: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n",
        "    \"\"\"\n",
        "    Extrae características de los coeficientes DWT.\n",
        "\n",
        "    Args:\n",
        "        dwt_coeffs: Diccionario con coeficientes DWT por nivel\n",
        "\n",
        "    Returns:\n",
        "        Diccionario con características extraídas\n",
        "    \"\"\"\n",
        "    features = {}\n",
        "\n",
        "    print(\"Extrayendo características DWT...\")\n",
        "\n",
        "    # 1. Energía por nivel de descomposición\n",
        "    for level_key, coeff_array in dwt_coeffs.items():\n",
        "        # Energía promedio por trial y canal\n",
        "        energy = np.mean(coeff_array**2, axis=2)  # (trials, channels)\n",
        "        features[f'dwt_energy_{level_key}'] = energy\n",
        "        print(f\"  - Energía {level_key}: {energy.shape}\")\n",
        "\n",
        "    # 2. Estadísticas por nivel\n",
        "    for level_key, coeff_array in dwt_coeffs.items():\n",
        "        # Media por trial y canal\n",
        "        mean_coeffs = np.mean(coeff_array, axis=2)  # (trials, channels)\n",
        "        features[f'dwt_mean_{level_key}'] = mean_coeffs\n",
        "\n",
        "        # Desviación estándar por trial y canal\n",
        "        std_coeffs = np.std(coeff_array, axis=2)  # (trials, channels)\n",
        "        features[f'dwt_std_{level_key}'] = std_coeffs\n",
        "\n",
        "        # Máximo absoluto por trial y canal\n",
        "        max_coeffs = np.max(np.abs(coeff_array), axis=2)  # (trials, channels)\n",
        "        features[f'dwt_max_{level_key}'] = max_coeffs\n",
        "\n",
        "        print(f\"  - Estadísticas {level_key}: media, std, max\")\n",
        "\n",
        "    # 3. Relación de energía entre niveles (aproximación de bandas de frecuencia)\n",
        "    if 'level_0' in dwt_coeffs and 'level_1' in dwt_coeffs:\n",
        "        # Relación entre aproximación y detalle\n",
        "        energy_level_0 = np.mean(dwt_coeffs['level_0']**2, axis=2)\n",
        "        energy_level_1 = np.mean(dwt_coeffs['level_1']**2, axis=2)\n",
        "        energy_ratio = energy_level_0 / (energy_level_1 + 1e-10)\n",
        "        features['dwt_energy_ratio_level0_level1'] = energy_ratio\n",
        "        print(f\"  - Relación de energía level0/level1: {energy_ratio.shape}\")\n",
        "\n",
        "    return features\n",
        "\n",
        "# Extraer características DWT\n",
        "dwt_features = extract_dwt_features(dwt_coeffs)\n",
        "\n",
        "print(f\"\\nCaracterísticas DWT extraídas:\")\n",
        "for feature_name, feature_array in dwt_features.items():\n",
        "    print(f\"  - {feature_name}: {feature_array.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpkL1jtQ8veF"
      },
      "source": [
        "## Preparación de Características para BoF\n",
        "\n",
        "Combinamos todas las características extraídas y las preparamos para Bag of Features:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "meeFFQFm8veF",
        "outputId": "a094ce16-39fc-48aa-ca72-cfa815a937c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Combinando características para BoF...\n",
            "Total de características extraídas: 36\n",
            "Matriz de características final:\n",
            "  - Trials: 880\n",
            "  - Características totales: 2304\n",
            "  - Primeras 10 características: ['cwt_energy_delta_FC5', 'cwt_energy_delta_FC3', 'cwt_energy_delta_FC1', 'cwt_energy_delta_FCZ', 'cwt_energy_delta_FC2', 'cwt_energy_delta_FC4', 'cwt_energy_delta_FC6', 'cwt_energy_delta_C5', 'cwt_energy_delta_C3', 'cwt_energy_delta_C1']\n",
            "Características normalizadas: (880, 2304)\n",
            "Media después de normalización: 0.000000\n",
            "Desviación estándar después de normalización: 1.000000\n"
          ]
        }
      ],
      "source": [
        "# Combinar todas las características\n",
        "print(\"Combinando características para BoF...\")\n",
        "\n",
        "# Combinar características CWT y DWT\n",
        "all_features = {}\n",
        "all_features.update(cwt_features)\n",
        "all_features.update(dwt_features)\n",
        "\n",
        "print(f\"Total de características extraídas: {len(all_features)}\")\n",
        "\n",
        "# Crear matriz de características para BoF\n",
        "feature_names = []\n",
        "feature_matrices = []\n",
        "\n",
        "for feature_name, feature_array in all_features.items():\n",
        "    # Reshape para tener una matriz 2D (samples, features)\n",
        "    if len(feature_array.shape) == 2:  # (trials, channels)\n",
        "        # Cada canal es una característica\n",
        "        for ch_idx, ch_name in enumerate(ch_names):\n",
        "            feature_names.append(f\"{feature_name}_{ch_name}\")\n",
        "            feature_matrices.append(feature_array[:, ch_idx])\n",
        "    elif len(feature_array.shape) == 3:  # (trials, channels, scales/levels)\n",
        "        # Cada combinación canal-escala es una característica\n",
        "        for ch_idx, ch_name in enumerate(ch_names):\n",
        "            for scale_idx in range(feature_array.shape[2]):\n",
        "                feature_names.append(f\"{feature_name}_{ch_name}_scale{scale_idx}\")\n",
        "                feature_matrices.append(feature_array[:, ch_idx, scale_idx])\n",
        "\n",
        "# Crear matriz final de características\n",
        "X_features = np.column_stack(feature_matrices)  # (trials, total_features)\n",
        "\n",
        "print(f\"Matriz de características final:\")\n",
        "print(f\"  - Trials: {X_features.shape[0]}\")\n",
        "print(f\"  - Características totales: {X_features.shape[1]}\")\n",
        "print(f\"  - Primeras 10 características: {feature_names[:10]}\")\n",
        "\n",
        "# Imputar NaNs por la media de cada columna antes de normalizar\n",
        "if np.isnan(X_features).any():\n",
        "    col_means = np.nanmean(X_features, axis=0)\n",
        "    inds = np.where(np.isnan(X_features))\n",
        "    X_features[inds] = np.take(col_means, inds[1])\n",
        "\n",
        "# Normalizar características\n",
        "scaler = StandardScaler()\n",
        "X_features_normalized = scaler.fit_transform(X_features)\n",
        "\n",
        "print(f\"Características normalizadas: {X_features_normalized.shape}\")\n",
        "print(f\"Media después de normalización: {np.mean(X_features_normalized):.6f}\")\n",
        "print(f\"Desviación estándar después de normalización: {np.std(X_features_normalized):.6f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMVNkMtW8veG"
      },
      "source": [
        "## Guardado de Archivos para BoF\n",
        "\n",
        "Guardamos las características y metadatos necesarios para implementar Bag of Features:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7BnrDXf8veG",
        "outputId": "59db7c00-dc90-4f57-d6e4-d3c1f14ede55"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Características guardadas: /Users/manueljurado/Downloads/datos_BCI/results/wavelets/wavelet_features.npy\n",
            "Nombres de características guardados: /Users/manueljurado/Downloads/datos_BCI/results/wavelets/feature_names.txt\n",
            "Información de canales guardada: /Users/manueljurado/Downloads/datos_BCI/results/wavelets/channel_info.csv\n",
            "Información de sujetos guardada: /Users/manueljurado/Downloads/datos_BCI/results/wavelets/subjects_info.csv\n",
            "Configuración guardada: /Users/manueljurado/Downloads/datos_BCI/results/wavelets/wavelet_config.json\n",
            "\n",
            "Resumen de archivos generados:\n",
            "  - wavelet_features.npy: Características normalizadas ((880, 2304))\n",
            "  - feature_names.txt: Nombres de características (2304 características)\n",
            "  - channel_info.csv: Información de canales (64 canales)\n",
            "  - subjects_info.csv: Información de sujetos (40 archivos)\n",
            "  - wavelet_config.json: Parámetros de configuración\n"
          ]
        }
      ],
      "source": [
        "# Guardar características normalizadas para BoF\n",
        "features_file = wavelet_output_dir / \"wavelet_features.npy\"\n",
        "np.save(features_file, X_features_normalized)\n",
        "print(f\"Características guardadas: {features_file.resolve()}\")\n",
        "\n",
        "# Guardar nombres de características\n",
        "feature_names_file = wavelet_output_dir / \"feature_names.txt\"\n",
        "with open(feature_names_file, 'w') as f:\n",
        "    for name in feature_names:\n",
        "        f.write(f\"{name}\\n\")\n",
        "print(f\"Nombres de características guardados: {feature_names_file.resolve()}\")\n",
        "\n",
        "# Guardar información de canales\n",
        "channel_info = pd.DataFrame({\n",
        "    'channel_index': range(len(ch_names)),\n",
        "    'channel_name': ch_names,\n",
        "    'region': ['unknown'] * len(ch_names)  # Se puede mejorar con mapeo de regiones\n",
        "})\n",
        "\n",
        "# Mapear regiones basado en prefijos\n",
        "for idx, ch_name in enumerate(ch_names):\n",
        "    ch_upper = ch_name.upper()\n",
        "    for region, prefixes in REGION_PREFIXES.items():\n",
        "        if any(ch_upper.startswith(p) for p in prefixes):\n",
        "            channel_info.loc[idx, 'region'] = region\n",
        "            break\n",
        "\n",
        "channel_info_file = wavelet_output_dir / \"channel_info.csv\"\n",
        "channel_info.to_csv(channel_info_file, index=False)\n",
        "print(f\"Información de canales guardada: {channel_info_file.resolve()}\")\n",
        "\n",
        "# Guardar información de sujetos y tareas\n",
        "subjects_df = pd.DataFrame(subjects_info)\n",
        "subjects_file = wavelet_output_dir / \"subjects_info.csv\"\n",
        "subjects_df.to_csv(subjects_file, index=False)\n",
        "print(f\"Información de sujetos guardada: {subjects_file.resolve()}\")\n",
        "\n",
        "# Guardar parámetros de configuración\n",
        "config_info = {\n",
        "    'cwt_scales': CWT_SCALES.tolist(),\n",
        "    'cwt_wavelet': CWT_WAVELET,\n",
        "    'cwt_width': CWT_WIDTH,\n",
        "    'dwt_wavelet': DWT_WAVELET,\n",
        "    'dwt_levels': DWT_LEVELS,\n",
        "    'freq_bands': FREQ_BANDS,\n",
        "    'sampling_rate': sfreq,\n",
        "    'n_trials': N,\n",
        "    'n_channels': C,\n",
        "    'n_timepoints': T,\n",
        "    'feature_dimensions': X_features_normalized.shape[1]\n",
        "}\n",
        "\n",
        "config_file = wavelet_output_dir / \"wavelet_config.json\"\n",
        "import json\n",
        "with open(config_file, 'w') as f:\n",
        "    json.dump(config_info, f, indent=2)\n",
        "print(f\"Configuración guardada: {config_file.resolve()}\")\n",
        "\n",
        "print(f\"\\nResumen de archivos generados:\")\n",
        "print(f\"  - {features_file.name}: Características normalizadas ({X_features_normalized.shape})\")\n",
        "print(f\"  - {feature_names_file.name}: Nombres de características ({len(feature_names)} características)\")\n",
        "print(f\"  - {channel_info_file.name}: Información de canales ({len(ch_names)} canales)\")\n",
        "print(f\"  - {subjects_file.name}: Información de sujetos ({len(subjects_info)} archivos)\")\n",
        "print(f\"  - {config_file.name}: Parámetros de configuración\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mi_3rXPz8veG"
      },
      "source": [
        "## Preparación de Datos para Bag of Features (BoF)\n",
        "\n",
        "Esta sección prepara específicamente los datos que necesita el algoritmo Bag of Features para clasificación:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rRpDdf58veG",
        "outputId": "744bedc1-3fbd-4ffc-b353-3a90ef47bbae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preparando datos específicos para Bag of Features...\n",
            "Directorio BoF: /Users/manueljurado/Downloads/datos_BCI/data/bof_features\n",
            "\n",
            "1. Creando etiquetas de clase...\n",
            "  - Etiquetas creadas: (880,)\n",
            "  - Clase 0 (left): 442 trials\n",
            "  - Clase 1 (right): 438 trials\n",
            "  - Etiquetas guardadas en: /Users/manueljurado/Downloads/datos_BCI/data/bof_features/y_labels.npy\n"
          ]
        }
      ],
      "source": [
        "# Usar variable global definida en celda 1 (usado por 03_BoF_Clasificacion.ipynb)\n",
        "bof_data_dir = BOF_DATA_DIR\n",
        "\n",
        "print(\"Preparando datos específicos para Bag of Features...\")\n",
        "print(f\"Directorio BoF: {bof_data_dir.resolve()}\")\n",
        "\n",
        "# 1. Crear etiquetas de clase basadas en la tarea (left/right)\n",
        "print(\"\\n1. Creando etiquetas de clase...\")\n",
        "\n",
        "# Crear array de etiquetas basado en subjects_info\n",
        "y_labels = []\n",
        "trial_to_subject = []  # Mapeo de trial a sujeto\n",
        "trial_to_task = []     # Mapeo de trial a tarea\n",
        "\n",
        "trial_idx = 0\n",
        "for subject_info in subjects_info:\n",
        "    n_trials = subject_info['n_trials']\n",
        "    task = subject_info['task']\n",
        "    subject = subject_info['subject']\n",
        "\n",
        "    # Etiquetas: 0 = left, 1 = right\n",
        "    label = 0 if task == 'left' else 1\n",
        "\n",
        "    for _ in range(n_trials):\n",
        "        y_labels.append(label)\n",
        "        trial_to_subject.append(subject)\n",
        "        trial_to_task.append(task)\n",
        "        trial_idx += 1\n",
        "\n",
        "y_labels = np.array(y_labels)\n",
        "print(f\"  - Etiquetas creadas: {y_labels.shape}\")\n",
        "print(f\"  - Clase 0 (left): {np.sum(y_labels == 0)} trials\")\n",
        "print(f\"  - Clase 1 (right): {np.sum(y_labels == 1)} trials\")\n",
        "\n",
        "# Guardar etiquetas\n",
        "np.save(bof_data_dir / \"y_labels.npy\", y_labels)\n",
        "np.save(bof_data_dir / \"trial_to_subject.npy\", np.array(trial_to_subject))\n",
        "np.save(bof_data_dir / \"trial_to_task.npy\", np.array(trial_to_task))\n",
        "\n",
        "print(f\"  - Etiquetas guardadas en: {bof_data_dir / 'y_labels.npy'}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7d6v-0P8veG",
        "outputId": "bed077b3-21f1-4c8c-b621-554d9b048c71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "2. Preparando características para BoF...\n",
            "  - cwt_energy_alpha: (880, 64)\n",
            "  - cwt_energy_beta: (880, 64)\n",
            "  - cwt_dominant_freq: (880, 64)\n",
            "  - cwt_spectral_entropy: (880, 64)\n",
            "  - dwt_energy_level_0: (880, 64)\n",
            "  - dwt_energy_level_1: (880, 64)\n",
            "  - dwt_energy_level_2: (880, 64)\n",
            "  - dwt_mean_level_0: (880, 64)\n",
            "  - dwt_std_level_0: (880, 64)\n",
            "\n",
            "Total de características seleccionadas: 9\n",
            "Matriz de características BoF:\n",
            "  - Trials: 880\n",
            "  - Características: 576\n",
            "  - Primeras 10 características: ['cwt_energy_alpha_FC5', 'cwt_energy_alpha_FC3', 'cwt_energy_alpha_FC1', 'cwt_energy_alpha_FCZ', 'cwt_energy_alpha_FC2', 'cwt_energy_alpha_FC4', 'cwt_energy_alpha_FC6', 'cwt_energy_alpha_C5', 'cwt_energy_alpha_C3', 'cwt_energy_alpha_C1']\n",
            "Características BoF normalizadas: (880, 576)\n",
            "Media después de normalización: 0.000000\n",
            "Desviación estándar: 1.000000\n"
          ]
        }
      ],
      "source": [
        "# 2. Preparar características específicas para BoF\n",
        "print(\"\\n2. Preparando características para BoF...\")\n",
        "\n",
        "# Seleccionar características más relevantes para BoF\n",
        "selected_features = {}\n",
        "\n",
        "# Características CWT más importantes\n",
        "cwt_key_features = [\n",
        "    'cwt_energy_alpha',    # Energía en banda alpha (8-13 Hz)\n",
        "    'cwt_energy_beta',    # Energía en banda beta (13-30 Hz)\n",
        "    'cwt_dominant_freq',  # Frecuencia dominante\n",
        "    'cwt_spectral_entropy' # Entropía espectral\n",
        "]\n",
        "\n",
        "for feature_name in cwt_key_features:\n",
        "    if feature_name in cwt_features:\n",
        "        selected_features[feature_name] = cwt_features[feature_name]\n",
        "        print(f\"  - {feature_name}: {cwt_features[feature_name].shape}\")\n",
        "\n",
        "# Características DWT más importantes (primeros 3 niveles)\n",
        "dwt_key_features = [\n",
        "    'dwt_energy_level_0',  # Aproximación (baja frecuencia)\n",
        "    'dwt_energy_level_1',  # Primer detalle\n",
        "    'dwt_energy_level_2',  # Segundo detalle\n",
        "    'dwt_mean_level_0',    # Media de aproximación\n",
        "    'dwt_std_level_0'      # Desviación estándar de aproximación\n",
        "]\n",
        "\n",
        "for feature_name in dwt_key_features:\n",
        "    if feature_name in dwt_features:\n",
        "        selected_features[feature_name] = dwt_features[feature_name]\n",
        "        print(f\"  - {feature_name}: {dwt_features[feature_name].shape}\")\n",
        "\n",
        "print(f\"\\nTotal de características seleccionadas: {len(selected_features)}\")\n",
        "\n",
        "# Crear matriz de características seleccionadas\n",
        "bof_feature_names = []\n",
        "bof_feature_matrices = []\n",
        "\n",
        "for feature_name, feature_array in selected_features.items():\n",
        "    if len(feature_array.shape) == 2:  # (trials, channels)\n",
        "        for ch_idx, ch_name in enumerate(ch_names):\n",
        "            bof_feature_names.append(f\"{feature_name}_{ch_name}\")\n",
        "            bof_feature_matrices.append(feature_array[:, ch_idx])\n",
        "    elif len(feature_array.shape) == 3:  # (trials, channels, scales)\n",
        "        for ch_idx, ch_name in enumerate(ch_names):\n",
        "            for scale_idx in range(feature_array.shape[2]):\n",
        "                bof_feature_names.append(f\"{feature_name}_{ch_name}_scale{scale_idx}\")\n",
        "                bof_feature_matrices.append(feature_array[:, ch_idx, scale_idx])\n",
        "\n",
        "# Crear matriz final de características BoF\n",
        "X_bof = np.column_stack(bof_feature_matrices)\n",
        "\n",
        "print(f\"Matriz de características BoF:\")\n",
        "print(f\"  - Trials: {X_bof.shape[0]}\")\n",
        "print(f\"  - Características: {X_bof.shape[1]}\")\n",
        "print(f\"  - Primeras 10 características: {bof_feature_names[:10]}\")\n",
        "\n",
        "# Imputar NaNs por la media de cada columna antes de normalizar\n",
        "if np.isnan(X_bof).any():\n",
        "    col_means_bof = np.nanmean(X_bof, axis=0)\n",
        "    inds_bof = np.where(np.isnan(X_bof))\n",
        "    X_bof[inds_bof] = np.take(col_means_bof, inds_bof[1])\n",
        "\n",
        "# Normalizar características BoF\n",
        "scaler_bof = StandardScaler()\n",
        "X_bof_normalized = scaler_bof.fit_transform(X_bof)\n",
        "\n",
        "print(f\"Características BoF normalizadas: {X_bof_normalized.shape}\")\n",
        "print(f\"Media después de normalización: {np.mean(X_bof_normalized):.6f}\")\n",
        "print(f\"Desviación estándar: {np.std(X_bof_normalized):.6f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47oicjuJ8veH",
        "outputId": "bb268d37-415c-4005-b608-696f36bb9bbc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "3. Guardando datos específicos para BoF...\n",
            "  - Características BoF: /Users/manueljurado/Downloads/datos_BCI/data/bof_features/X_bof_features.npy\n",
            "  - Nombres de características: /Users/manueljurado/Downloads/datos_BCI/data/bof_features/bof_feature_names.txt\n",
            "  - Normalizador BoF: /Users/manueljurado/Downloads/datos_BCI/data/bof_features/scaler_bof.pkl\n",
            "  - Metadatos BoF: /Users/manueljurado/Downloads/datos_BCI/data/bof_features/bof_metadata.json\n",
            "  - Configuración BoF: /Users/manueljurado/Downloads/datos_BCI/data/bof_features/bof_config.json\n",
            "\n",
            "Datos BoF guardados exitosamente en: /Users/manueljurado/Downloads/datos_BCI/data/bof_features\n"
          ]
        }
      ],
      "source": [
        "# 3. Guardar datos específicos para BoF\n",
        "print(\"\\n3. Guardando datos específicos para BoF...\")\n",
        "\n",
        "# Guardar características BoF\n",
        "np.save(bof_data_dir / \"X_bof_features.npy\", X_bof_normalized)\n",
        "print(f\"  - Características BoF: {bof_data_dir / 'X_bof_features.npy'}\")\n",
        "\n",
        "# Guardar nombres de características BoF\n",
        "with open(bof_data_dir / \"bof_feature_names.txt\", 'w') as f:\n",
        "    for name in bof_feature_names:\n",
        "        f.write(f\"{name}\\n\")\n",
        "print(f\"  - Nombres de características: {bof_data_dir / 'bof_feature_names.txt'}\")\n",
        "\n",
        "# Guardar normalizador BoF\n",
        "import pickle\n",
        "with open(bof_data_dir / \"scaler_bof.pkl\", 'wb') as f:\n",
        "    pickle.dump(scaler_bof, f)\n",
        "print(f\"  - Normalizador BoF: {bof_data_dir / 'scaler_bof.pkl'}\")\n",
        "\n",
        "# Crear información de metadatos para BoF\n",
        "bof_metadata = {\n",
        "    'n_trials': X_bof_normalized.shape[0],\n",
        "    'n_features': X_bof_normalized.shape[1],\n",
        "    'n_channels': len(ch_names),\n",
        "    'n_subjects': len(subjects_info),\n",
        "    'class_distribution': {\n",
        "        'left_trials': int(np.sum(y_labels == 0)),\n",
        "        'right_trials': int(np.sum(y_labels == 1))\n",
        "    },\n",
        "    'feature_types': {\n",
        "        'cwt_features': len([f for f in bof_feature_names if f.startswith('cwt_')]),\n",
        "        'dwt_features': len([f for f in bof_feature_names if f.startswith('dwt_')])\n",
        "    },\n",
        "    'sampling_rate': sfreq,\n",
        "    'trial_duration_sec': T / sfreq,\n",
        "    'wavelet_config': {\n",
        "        'cwt_scales': len(CWT_SCALES),\n",
        "        'cwt_wavelet': CWT_WAVELET,\n",
        "        'dwt_levels': DWT_LEVELS,\n",
        "        'dwt_wavelet': DWT_WAVELET\n",
        "    }\n",
        "}\n",
        "\n",
        "with open(bof_data_dir / \"bof_metadata.json\", 'w') as f:\n",
        "    json.dump(bof_metadata, f, indent=2)\n",
        "print(f\"  - Metadatos BoF: {bof_data_dir / 'bof_metadata.json'}\")\n",
        "\n",
        "# Crear archivo de configuración para BoF\n",
        "bof_config = {\n",
        "    'data_files': {\n",
        "        'features': 'X_bof_features.npy',\n",
        "        'labels': 'y_labels.npy',\n",
        "        'feature_names': 'bof_feature_names.txt',\n",
        "        'scaler': 'scaler_bof.pkl',\n",
        "        'metadata': 'bof_metadata.json'\n",
        "    },\n",
        "    'recommended_params': {\n",
        "        'n_clusters': [50, 100, 200],  # Número de clusters para BoF\n",
        "        'random_state': 42,\n",
        "        'test_size': 0.2,\n",
        "        'cv_folds': 5\n",
        "    },\n",
        "    'feature_info': {\n",
        "        'total_features': len(bof_feature_names),\n",
        "        'cwt_features': len([f for f in bof_feature_names if f.startswith('cwt_')]),\n",
        "        'dwt_features': len([f for f in bof_feature_names if f.startswith('dwt_')]),\n",
        "        'normalized': True,\n",
        "        'scaler_type': 'StandardScaler'\n",
        "    }\n",
        "}\n",
        "\n",
        "with open(bof_data_dir / \"bof_config.json\", 'w') as f:\n",
        "    json.dump(bof_config, f, indent=2)\n",
        "print(f\"  - Configuración BoF: {bof_data_dir / 'bof_config.json'}\")\n",
        "\n",
        "print(f\"\\nDatos BoF guardados exitosamente en: {bof_data_dir.resolve()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGlECWOS8veH"
      },
      "source": [
        "## Resumen del Análisis de Wavelets y Preparación BoF\n",
        "\n",
        "### Análisis Completados\n",
        "\n",
        "1. **Transformada Wavelet Continua (CWT)**\n",
        "   - Wavelet de Morlet con 50 escalas logarítmicas\n",
        "   - Análisis tiempo-frecuencia completo\n",
        "   - Extracción de energía por banda, frecuencia dominante y entropía espectral\n",
        "\n",
        "2. **Transformada Wavelet Discreta (DWT)**\n",
        "   - Wavelet Daubechies 4 con 6 niveles de descomposición\n",
        "   - Análisis multiresolución\n",
        "   - Extracción de estadísticas por nivel (energía, media, desviación estándar, máximo)\n",
        "\n",
        "3. **Preparación Específica para BoF**\n",
        "   - Selección de características más relevantes\n",
        "   - Normalización específica para BoF\n",
        "   - Etiquetas de clase (left/right)\n",
        "   - Metadatos completos y configuración\n",
        "\n",
        "### Archivos Generados para BoF\n",
        "\n",
        "Todos los archivos específicos para BoF se guardaron en el directorio `bof_data/`:\n",
        "\n",
        "- **`X_bof_features.npy`**: Características normalizadas específicas para BoF\n",
        "- **`y_labels.npy`**: Etiquetas de clase (0=left, 1=right)\n",
        "- **`bof_feature_names.txt`**: Nombres de características seleccionadas\n",
        "- **`scaler_bof.pkl`**: Normalizador entrenado para BoF\n",
        "- **`bof_metadata.json`**: Metadatos completos del dataset\n",
        "- **`bof_config.json`**: Configuración y parámetros recomendados\n",
        "- **`trial_to_subject.npy`**: Mapeo de trials a sujetos\n",
        "- **`trial_to_task.npy`**: Mapeo de trials a tareas\n",
        "\n",
        "### Características Seleccionadas para BoF\n",
        "\n",
        "**CWT Features:**\n",
        "- Energía en banda alpha (8-13 Hz)\n",
        "- Energía en banda beta (13-30 Hz)\n",
        "- Frecuencia dominante por canal\n",
        "- Entropía espectral por canal\n",
        "\n",
        "**DWT Features:**\n",
        "- Energía de aproximación (nivel 0)\n",
        "- Energía de detalles (niveles 1-2)\n",
        "- Media y desviación estándar de aproximación\n",
        "\n",
        "### Próximos Pasos para BoF\n",
        "\n",
        "Los datos están completamente preparados para implementar Bag of Features:\n",
        "\n",
        "1. **Cargar datos**: Usar archivos en `bof_data/`\n",
        "2. **Clustering**: Aplicar K-means con parámetros recomendados\n",
        "3. **Codificación**: Crear histogramas de características por trial\n",
        "4. **Clasificación**: Entrenar clasificadores SVM/Random Forest\n",
        "5. **Evaluación**: Validación cruzada y métricas de rendimiento\n",
        "\n",
        "### Variables Disponibles para BoF\n",
        "\n",
        "- `X_bof_normalized`: Características normalizadas para BoF\n",
        "- `y_labels`: Etiquetas de clase\n",
        "- `bof_feature_names`: Nombres de características\n",
        "- `scaler_bof`: Normalizador entrenado\n",
        "- `bof_metadata`: Metadatos del dataset\n",
        "- `bof_config`: Configuración recomendada\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
