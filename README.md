# An√°lisis de Datos MI-EEG con Wavelets (Notebooks)

Este proyecto analiza datos de interfaz cerebro-computadora (BCI) de imaginaci√≥n motora (MI) usando EEGLAB, implementando an√°lisis exploratorio y transformadas wavelet mediante notebooks de Jupyter. El proyecto est√° completamente preparado para la implementaci√≥n de Bag of Features con datos optimizados.

## Estructura del Proyecto

```
datos_BCI/
‚îú‚îÄ‚îÄ 01_EDA_Analysis.ipynb           # Notebook: An√°lisis exploratorio (PSD, correlaci√≥n)
‚îú‚îÄ‚îÄ 02_Wavelet_Analysis.ipynb       # Notebook: An√°lisis de wavelets (CWT y DWT)
‚îú‚îÄ‚îÄ bof_template.py                 # Template para implementar Bag of Features
‚îú‚îÄ‚îÄ left_imag/                      # Datos de imaginaci√≥n motora mano izquierda (20 archivos)
‚îú‚îÄ‚îÄ right_imag/                     # Datos de imaginaci√≥n motora mano derecha (20 archivos)
‚îú‚îÄ‚îÄ venv/                           # Entorno virtual Python
‚îú‚îÄ‚îÄ pyproject.toml                  # Configuraci√≥n del proyecto y dependencias
‚îú‚îÄ‚îÄ README.md                       # Este archivo
‚îú‚îÄ‚îÄ shared_data/                    # Datos compartidos entre notebooks
‚îÇ   ‚îú‚îÄ‚îÄ X_data.npy                  # Datos concatenados (trials, channels, time)
‚îÇ   ‚îú‚îÄ‚îÄ ch_names.npy                # Nombres de canales
‚îÇ   ‚îú‚îÄ‚îÄ sfreq.npy                   # Frecuencia de muestreo
‚îÇ   ‚îú‚îÄ‚îÄ data_dimensions.npy         # Dimensiones de los datos
‚îÇ   ‚îú‚îÄ‚îÄ subjects_info.csv           # Informaci√≥n de sujetos
‚îÇ   ‚îú‚îÄ‚îÄ region_info.json            # Informaci√≥n de regiones cerebrales
‚îÇ   ‚îî‚îÄ‚îÄ config_params.json          # Par√°metros de configuraci√≥n
‚îú‚îÄ‚îÄ bof_data/                       # Datos espec√≠ficos para Bag of Features
‚îÇ   ‚îú‚îÄ‚îÄ X_bof_features.npy          # Caracter√≠sticas normalizadas para BoF
‚îÇ   ‚îú‚îÄ‚îÄ y_labels.npy                # Etiquetas de clase (0=left, 1=right)
‚îÇ   ‚îú‚îÄ‚îÄ bof_feature_names.txt       # Nombres de caracter√≠sticas seleccionadas
‚îÇ   ‚îú‚îÄ‚îÄ scaler_bof.pkl              # Normalizador entrenado para BoF
‚îÇ   ‚îú‚îÄ‚îÄ bof_metadata.json           # Metadatos completos del dataset
‚îÇ   ‚îú‚îÄ‚îÄ bof_config.json             # Configuraci√≥n y par√°metros recomendados
‚îÇ   ‚îú‚îÄ‚îÄ trial_to_subject.npy        # Mapeo de trials a sujetos
‚îÇ   ‚îî‚îÄ‚îÄ trial_to_task.npy           # Mapeo de trials a tareas
‚îú‚îÄ‚îÄ reports/                        # Directorio de salida EDA
‚îÇ   ‚îú‚îÄ‚îÄ psd_avg.png                 # PSD promedio con bandas Œº/Œ≤
‚îÇ   ‚îú‚îÄ‚îÄ corr_heatmap.png            # Mapa de calor de correlaci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ psd_bandpower_per_channel.csv # Potencia por banda y canal
‚îÇ   ‚îî‚îÄ‚îÄ corr_region_summary.txt     # Resumen de correlaciones por regi√≥n
‚îî‚îÄ‚îÄ wavelet_reports/                # Directorio de salida wavelets (generado por notebook)
    ‚îú‚îÄ‚îÄ wavelet_features.npy        # Caracter√≠sticas normalizadas para BoF
    ‚îú‚îÄ‚îÄ feature_names.txt           # Nombres de caracter√≠sticas
    ‚îú‚îÄ‚îÄ channel_info.csv            # Informaci√≥n de canales y regiones
    ‚îú‚îÄ‚îÄ subjects_info.csv           # Informaci√≥n de sujetos y tareas
    ‚îî‚îÄ‚îÄ wavelet_config.json         # Par√°metros de configuraci√≥n wavelets
```

## Configuraci√≥n del Entorno

### Opci√≥n 1: Usando el entorno virtual (Recomendado)
```bash
# Activar entorno virtual existente
source venv/bin/activate

# Las dependencias ya est√°n instaladas
```

### Opci√≥n 2: Instalaci√≥n manual
```bash
# Instalar dependencias principales
pip install mne PyWavelets scikit-learn matplotlib pandas numpy scipy tqdm

# O usar pyproject.toml
pip install -e .
```

### Opci√≥n 3: Desde los notebooks
Si ejecutas los notebooks en un entorno nuevo, ejecuta la **primera celda** de cada notebook que contiene la instalaci√≥n autom√°tica:

**Celda 1 - Instalaci√≥n de dependencias:**
```python
# Celda de instalaci√≥n de dependencias
# Ejecutar esta celda SOLO si necesitas instalar las librer√≠as en un entorno nuevo

%pip install mne
%pip install PyWavelets
%pip install scikit-learn
%pip install matplotlib
%pip install pandas
%pip install numpy
%pip install scipy
%pip install tqdm

print("Instalaci√≥n de dependencias completada")
```

**Celda 2 - Importaci√≥n de librer√≠as:**
```python
# Importar librer√≠as necesarias
import os
import re
# ... resto de imports
```

### Crear entorno virtual nuevo (si es necesario)
```bash
# Crear entorno virtual
python3 -m venv venv
source venv/bin/activate

# Instalar dependencias
pip install -e .
```

## Configuraci√≥n del Proyecto

Este proyecto utiliza `pyproject.toml` para la gesti√≥n de dependencias y configuraci√≥n, siguiendo las mejores pr√°cticas modernas de Python.

### Dependencias principales:
- `mne>=1.5.0`: Para procesamiento de se√±ales EEG
- `scipy>=1.11.0`: Operaciones cient√≠ficas
- `numpy>=1.24.0`: Arrays num√©ricos
- `matplotlib>=3.7.0`: Visualizaci√≥n
- `seaborn>=0.12.0`: Visualizaci√≥n estad√≠stica
- `pandas>=2.0.0`: Manipulaci√≥n de datos
- `tqdm>=4.65.0`: Barras de progreso
- `PyWavelets>=1.4.0`: Transformadas wavelet
- `scikit-learn>=1.3.0`: Machine learning y clustering

### Dependencias de desarrollo (opcionales):
- `pytest>=7.0.0`: Testing
- `black>=22.0.0`: Formateador de c√≥digo
- `flake8>=4.0.0`: Linter
- `mypy>=0.950`: Verificaci√≥n de tipos

### Ventajas de pyproject.toml:
- ‚úÖ **Est√°ndar moderno**: PEP 518/621 compliant
- ‚úÖ **Metadatos completos**: Informaci√≥n del proyecto, autores, descripci√≥n
- ‚úÖ **Herramientas integradas**: Configuraci√≥n para Black, MyPy, etc.
- ‚úÖ **Gesti√≥n de dependencias**: Dependencias principales y opcionales
- ‚úÖ **Instalaci√≥n editable**: `pip install -e .` para desarrollo
- ‚úÖ **Estructura simplificada**: F√°cil de mantener y usar

## An√°lisis Realizado

### 1. An√°lisis Exploratorio de Datos (EDA) - `eda.py`

El script `eda.py` realiza un an√°lisis espectral y de correlaci√≥n que incluye:

1. **An√°lisis espectral (PSD)**: 
   - Densidad espectral de potencia en 8-30 Hz
   - An√°lisis de bandas Œº (10-12 Hz) y Œ≤ (18-26 Hz)
   - Picos por canal en cada banda

2. **Correlaci√≥n intercanal**:
   - Mapa de calor de correlaci√≥n entre canales
   - Resumen por regiones cerebrales (Frontal, Central, Parietal, Occipital)

3. **Resultados** (guardados en `reports/`):
   - `psd_avg.png`: PSD promedio con bandas Œº/Œ≤ sombreadas
   - `corr_heatmap.png`: Mapa de calor de correlaci√≥n intercanal
   - `psd_bandpower_per_channel.csv`: Potencia media por banda y picos por canal
   - `corr_region_summary.txt`: Resumen de correlaciones por regiones

### 2. An√°lisis de Wavelets - `wavelet_analysis.py`

El script `wavelet_analysis.py` implementa an√°lisis avanzado de wavelets:

1. **Transformada Wavelet Continua (CWT)**:
   - An√°lisis tiempo-frecuencia usando wavelet de Morlet
   - Escalas logar√≠tmicas para cobertura completa del espectro
   - Extracci√≥n de caracter√≠sticas por bandas de frecuencia

2. **Transformada Wavelet Discreta (DWT)**:
   - Descomposici√≥n multiresoluci√≥n usando Daubechies 4
   - An√°lisis por niveles de descomposici√≥n
   - Caracter√≠sticas estad√≠sticas por nivel

3. **Caracter√≠sticas extra√≠das**:
   - Energ√≠a por banda de frecuencia (delta, theta, alpha, beta, gamma)
   - Potencia m√°xima por escala
   - Frecuencia dominante
   - Entrop√≠a espectral
   - Estad√≠sticas por nivel DWT

4. **Resultados** (guardados en `wavelet_reports/`):
   - `wavelet_features.csv`: Caracter√≠sticas extra√≠das para BoF
   - `wavelet_spectrogram.png`: Espectrograma wavelet promedio
   - `wavelet_energy_distribution.png`: Distribuci√≥n de energ√≠a por escalas
   - `wavelet_cwt_coefficients.npy`: Coeficientes CWT completos (opcional)
   - `wavelet_dwt_coefficients.npy`: Coeficientes DWT completos (opcional)

## Pr√≥ximos Pasos: Implementaci√≥n de Bag of Features (BoF)

El proyecto est√° preparado para implementar Bag of Features como siguiente paso. Las caracter√≠sticas wavelet extra√≠das est√°n listas para ser utilizadas en el pipeline BoF.

### Archivos Preparados para BoF

El an√°lisis de wavelets genera los siguientes archivos que ser√°n utilizados por BoF:

- **`wavelet_reports/wavelet_features.csv`**: Caracter√≠sticas extra√≠das por trial y canal
- **`wavelet_reports/wavelet_features_matrix.npy`**: Matriz de caracter√≠sticas en formato numpy
- **`wavelet_reports/channel_info.csv`**: Informaci√≥n de canales EEG

### Implementaci√≥n Sugerida de BoF

Para implementar Bag of Features, se recomienda crear un script `bof_classification.py` que incluya:

1. **Construcci√≥n del vocabulario visual**:
   - Cargar caracter√≠sticas desde `wavelet_features.csv`
   - Aplicar clustering K-means para crear vocabulario visual
   - Normalizar caracter√≠sticas antes del clustering

2. **Codificaci√≥n de caracter√≠sticas**:
   - Convertir caracter√≠sticas a histogramas de palabras visuales
   - Normalizar histogramas para clasificaci√≥n
   - Preparar datos para entrenamiento/test

3. **Clasificaci√≥n**:
   - Implementar m√∫ltiples algoritmos (SVM, Random Forest, Logistic Regression)
   - Divisi√≥n train/test estratificada
   - Validaci√≥n cruzada opcional

4. **Evaluaci√≥n**:
   - M√©tricas: accuracy, precision, recall, F1-score, AUC
   - Matrices de confusi√≥n
   - Curvas ROC
   - Importancia de caracter√≠sticas

5. **Visualizaci√≥n**:
   - PCA para visualizaci√≥n de histogramas BoF
   - Distribuci√≥n de palabras visuales
   - Comparaci√≥n de rendimiento entre algoritmos

### Template de Implementaci√≥n

Se incluye un archivo template `bof_template.py` que muestra la estructura completa para implementar BoF:

```bash
# Copiar template y completar implementaci√≥n
cp bof_template.py bof_classification.py

# Editar bof_classification.py para completar las funciones marcadas con TODO
# Ejecutar implementaci√≥n
python bof_classification.py
```

El template incluye:
- Clase `BagOfFeatures` con m√©todos para vocabulario y codificaci√≥n
- Funciones para carga de caracter√≠sticas wavelet
- Pipeline de entrenamiento y evaluaci√≥n
- Estructura para m√∫ltiples clasificadores (SVM, Random Forest, Logistic Regression)
- Marcadores TODO para guiar la implementaci√≥n

### Estructura del Template

```python
# bof_template.py
class BagOfFeatures:
    def __init__(self, vocab_size=50):
        # TODO: Inicializar componentes
    
    def build_vocabulary(self, features):
        # TODO: Implementar clustering K-means
    
    def encode_features(self, features):
        # TODO: Convertir a histogramas BoF

def load_wavelet_features(features_file):
    # TODO: Cargar caracter√≠sticas desde CSV

def train_classifiers(X_train, y_train):
    # TODO: Entrenar m√∫ltiples clasificadores

def evaluate_classifiers(classifiers, X_test, y_test):
    # TODO: Evaluar y visualizar resultados
```

## Configuraci√≥n del An√°lisis

El an√°lisis est√° configurado para:
- **Bandas de frecuencia**: 8-30 Hz (filtro Œº/Œ≤)
- **Banda Œº**: 10-12 Hz
- **Banda Œ≤**: 18-26 Hz
- **Ventana de trial**: 9 segundos por defecto
- **M√©todo PSD**: Welch con segmentos de 2 segundos y 50% overlap

## Uso

### Ejecutar Notebooks

#### 1. An√°lisis Exploratorio (EDA)
```bash
# Activar entorno virtual
source venv/bin/activate

# Ejecutar notebook de EDA
jupyter notebook 01_EDA_Analysis.ipynb

# O ejecutar directamente
jupyter nbconvert --to notebook --execute 01_EDA_Analysis.ipynb
```

#### 2. An√°lisis de Wavelets
```bash
# Ejecutar notebook de wavelets
jupyter notebook 02_Wavelet_Analysis.ipynb

# O ejecutar directamente
jupyter nbconvert --to notebook --execute 02_Wavelet_Analysis.ipynb
```

### Pipeline Recomendado

```bash
# 1. Activar entorno virtual
source venv/bin/activate

# 2. Ejecutar an√°lisis exploratorio (genera datos compartidos)
jupyter nbconvert --to notebook --execute 01_EDA_Analysis.ipynb

# 3. Ejecutar an√°lisis de wavelets (usa datos del EDA)
jupyter nbconvert --to notebook --execute 02_Wavelet_Analysis.ipynb

# 4. Implementar Bag of Features
# Los archivos en bof_data/ est√°n listos para implementar BoF
```

**Nota importante**: 
- El notebook de wavelets depende de los datos generados por el EDA
- Siempre ejecuta primero `01_EDA_Analysis.ipynb` para generar el directorio `shared_data/`
- Los datos espec√≠ficos para BoF se generan en `bof_data/` despu√©s de ejecutar el an√°lisis de wavelets

### Desarrollo Interactivo

```bash
# Iniciar Jupyter Lab para desarrollo interactivo
source venv/bin/activate
jupyter lab

# O Jupyter Notebook cl√°sico
jupyter notebook
```

## Datos

- **left_imag/**: 20 archivos .set/.fdt con datos de imaginaci√≥n motora mano izquierda
- **right_imag/**: 20 archivos .set/.fdt con datos de imaginaci√≥n motora mano derecha
- Cada archivo corresponde a un sujeto (S001-S020)
- Los archivos est√°n en formato EEGLAB (.set/.fdt)

## Estado Actual del Proyecto

### ‚úÖ Implementado

1. **An√°lisis Exploratorio de Datos (EDA)** - `01_EDA_Analysis.ipynb`
   - An√°lisis espectral (PSD) con bandas Œº/Œ≤
   - Correlaci√≥n intercanal
   - Visualizaciones y reportes
   - Generaci√≥n de datos compartidos
   - ‚úÖ **Completado**

2. **An√°lisis de Wavelets** - `02_Wavelet_Analysis.ipynb`
   - Transformada Wavelet Continua (CWT) con Morlet
   - Transformada Wavelet Discreta (DWT) con Daubechies 4
   - Extracci√≥n de caracter√≠sticas por bandas de frecuencia
   - Preparaci√≥n espec√≠fica de datos para BoF
   - ‚úÖ **Completado**

3. **Preparaci√≥n Completa para BoF**
   - Template completo en `bof_template.py`
   - Datos espec√≠ficos optimizados en `bof_data/`
   - Caracter√≠sticas seleccionadas y normalizadas
   - Etiquetas de clase y metadatos completos
   - ‚úÖ **Listo para implementar**

### üîÑ Pr√≥ximo Paso: Bag of Features

El proyecto est√° completamente preparado para implementar Bag of Features. Los archivos generados por el an√°lisis de wavelets contienen todas las caracter√≠sticas necesarias:

- **Caracter√≠sticas CWT**: Energ√≠a por banda, frecuencia dominante, entrop√≠a espectral
- **Caracter√≠sticas DWT**: Energ√≠a y estad√≠sticas por nivel de descomposici√≥n
- **Formato preparado**: CSV con caracter√≠sticas por trial y canal, matriz numpy para procesamiento eficiente

### üìã Archivos Listos para BoF

Despu√©s de ejecutar `python wavelet_analysis.py`, tendr√°s:

```
wavelet_reports/
‚îú‚îÄ‚îÄ wavelet_features.csv         # ‚Üê Archivo principal para BoF
‚îú‚îÄ‚îÄ wavelet_features_matrix.npy  # ‚Üê Matriz numpy para clustering
‚îú‚îÄ‚îÄ channel_info.csv            # ‚Üê Informaci√≥n de canales
‚îú‚îÄ‚îÄ wavelet_spectrogram.png     # ‚Üê Visualizaci√≥n CWT
‚îî‚îÄ‚îÄ wavelet_energy_distribution.png # ‚Üê Distribuci√≥n de energ√≠a
```

## Notas

- El script procesa todos los archivos disponibles en ambos directorios
- Los datos ya vienen epocados o se segmentan autom√°ticamente si son continuos
- Los resultados se guardan en directorios separados (`reports/` y `wavelet_reports/`)
- Los directorios de salida se crean autom√°ticamente si no existen
- Las caracter√≠sticas wavelet est√°n optimizadas para clustering K-means