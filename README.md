# Clasificaci√≥n de Se√±ales EEG de Imaginaci√≥n Motora: Bag of Features vs. Deep Learning

Este proyecto implementa y compara dos enfoques metodol√≥gicos para la clasificaci√≥n de se√±ales de electroencefalograf√≠a (EEG) durante tareas de imaginaci√≥n motora (MI): un modelo basado en **Bag of Features (BoF) combinado con SVM** y una arquitectura de **Red Neuronal Convolucional (DeepConvNet)**.

## üìã Descripci√≥n del Proyecto

El objetivo principal es clasificar se√±ales EEG en dos clases: **imaginaci√≥n de movimiento de mano izquierda (MI-L)** y **imaginaci√≥n de movimiento de mano derecha (MI-R)**. Se utilizan datos de 20 sujetos sanos, cada uno con 22 ensayos por tarea (880 ensayos totales), registrados mediante 64 electrodos con una frecuencia de muestreo de 128 Hz.

### Enfoques Implementados

1. **BoF-SVM**: Extracci√≥n de caracter√≠sticas mediante transformadas wavelet (CWT y DWT), representaci√≥n mediante Bag of Features, y clasificaci√≥n con M√°quinas de Vectores de Soporte (SVM).
2. **DeepConvNet**: Arquitectura de red neuronal convolucional profunda que aprende representaciones directamente de las se√±ales EEG preprocesadas.

### Resultados Principales

- **BoF-SVM**: Accuracy: 52.84%, F1-Score: 0.5451
- **DeepConvNet**: Accuracy: 67.42%, F1-Score: 0.6742

El modelo DeepConvNet demostr√≥ un mejor desempe√±o en todas las m√©tricas evaluadas, superando al modelo BoF-SVM por aproximadamente 15 puntos porcentuales en accuracy.

## üèóÔ∏è Estructura del Proyecto

```
datos_BCI/
‚îú‚îÄ‚îÄ Notebooks de An√°lisis
‚îÇ   ‚îú‚îÄ‚îÄ 01_EDA_Analysis.ipynb           # An√°lisis exploratorio (PSD, correlaci√≥n)
‚îÇ   ‚îú‚îÄ‚îÄ 02_Wavelet_Analysis.ipynb       # Extracci√≥n de caracter√≠sticas wavelet
‚îÇ   ‚îú‚îÄ‚îÄ 03_BoF_Clasificacion.ipynb      # Modelo Bag of Features + SVM
‚îÇ   ‚îî‚îÄ‚îÄ 04_DeepConvNet_CNN.ipynb        # Modelo DeepConvNet (CNN)
‚îÇ
‚îú‚îÄ‚îÄ Datos de Entrada
‚îÇ   ‚îú‚îÄ‚îÄ left_imag/                      # 20 archivos .set/.fdt (mano izquierda)
‚îÇ   ‚îî‚îÄ‚îÄ right_imag/                     # 20 archivos .set/.fdt (mano derecha)
‚îÇ
‚îú‚îÄ‚îÄ Datos Procesados (generados por los notebooks)
‚îÇ   ‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ preprocessed/               # Datos preprocesados
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ bof_features/               # Caracter√≠sticas para BoF
‚îÇ   ‚îî‚îÄ‚îÄ results/
‚îÇ       ‚îú‚îÄ‚îÄ eda/                        # Resultados an√°lisis exploratorio
‚îÇ       ‚îú‚îÄ‚îÄ wavelets/                   # Resultados an√°lisis wavelet
‚îÇ       ‚îú‚îÄ‚îÄ bof_svm/                    # Resultados BoF-SVM
‚îÇ       ‚îú‚îÄ‚îÄ deepconvnet/                # Resultados DeepConvNet
‚îÇ       ‚îî‚îÄ‚îÄ figures/                    # Gr√°ficas para el art√≠culo
‚îÇ
‚îú‚îÄ‚îÄ Documentaci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ README.md                       # Este archivo
‚îÇ   ‚îú‚îÄ‚îÄ articulo.md                     # Art√≠culo cient√≠fico en LaTeX
‚îÇ   ‚îú‚îÄ‚îÄ pyproject.toml                  # Dependencias del proyecto
‚îÇ   ‚îî‚îÄ‚îÄ venv/                           # Entorno virtual Python
‚îÇ
‚îî‚îÄ‚îÄ Archivos de Configuraci√≥n
    ‚îî‚îÄ‚îÄ .gitignore
```

## üöÄ Inicio R√°pido

### Requisitos Previos

- Python 3.11 o superior
- pip (gestor de paquetes de Python)
- Jupyter Notebook o Jupyter Lab

### Instalaci√≥n

#### Opci√≥n 1: Usar el entorno virtual existente (Recomendado)

```bash
# Clonar o descargar el proyecto
cd datos_BCI

# Activar el entorno virtual
source venv/bin/activate  # En macOS/Linux
# O: venv\Scripts\activate  # En Windows

# Las dependencias ya est√°n instaladas
```

#### Opci√≥n 2: Crear un entorno virtual nuevo

```bash
# Crear entorno virtual con Python 3.11
python3.11 -m venv venv
source venv/bin/activate  # macOS/Linux
# O: venv\Scripts\activate  # Windows

# Actualizar pip
pip install --upgrade pip

# Instalar dependencias desde pyproject.toml
pip install -e .

# Las dependencias se instalar√°n autom√°ticamente seg√∫n pyproject.toml:
# - mne>=1.10.0, scipy>=1.16.0, numpy>=1.26.0
# - matplotlib>=3.10.0, seaborn>=0.13.0, pandas>=2.3.0
# - PyWavelets>=1.9.0, scikit-learn>=1.7.0
# - torch>=2.2.0, jupyter>=1.1.0, tqdm>=4.67.0
```

#### Opci√≥n 3: Instalaci√≥n desde notebooks

Si ejecutas los notebooks en un entorno nuevo, ejecuta la **primera celda** de cada notebook que instala las dependencias autom√°ticamente.

### Ejecuci√≥n del Pipeline Completo

El proyecto sigue un pipeline secuencial. **Es importante ejecutar los notebooks en orden**:

```bash
# 1. Activar entorno virtual
source venv/bin/activate

# 2. Iniciar Jupyter
jupyter notebook
# O: jupyter lab

# 3. Ejecutar notebooks en orden:
#    a) 01_EDA_Analysis.ipynb
#    b) 02_Wavelet_Analysis.ipynb
#    c) 03_BoF_Clasificacion.ipynb
#    d) 04_DeepConvNet_CNN.ipynb
```

#### Ejecuci√≥n Automatizada (sin interfaz gr√°fica)

```bash
# Ejecutar todos los notebooks en orden
jupyter nbconvert --to notebook --execute 01_EDA_Analysis.ipynb
jupyter nbconvert --to notebook --execute 02_Wavelet_Analysis.ipynb
jupyter nbconvert --to notebook --execute 03_BoF_Clasificacion.ipynb
jupyter nbconvert --to notebook --execute 04_DeepConvNet_CNN.ipynb
```

## üìö Descripci√≥n Detallada de los Notebooks

### 1. An√°lisis Exploratorio (EDA) - `01_EDA_Analysis.ipynb`

**Objetivo**: Analizar las caracter√≠sticas b√°sicas de los datos EEG y verificar su calidad.

**Qu√© hace**:
- Carga los archivos .set/.fdt desde `left_imag/` y `right_imag/`
- Calcula la Densidad Espectral de Potencia (PSD) usando el m√©todo de Welch
- Analiza las bandas de frecuencia Œº (10-12 Hz) y Œ≤ (18-26 Hz)
- Calcula correlaciones intercanales
- Genera visualizaciones y reportes

**Salidas** (en `results/eda/`):
- `psd_avg.png`: Gr√°fico de PSD promedio
- `corr_heatmap.png`: Mapa de calor de correlaciones
- `psd_bandpower_per_channel.csv`: Potencia por banda y canal

**Tiempo estimado**: 5-10 minutos

### 2. An√°lisis de Wavelets - `02_Wavelet_Analysis.ipynb`

**Objetivo**: Extraer caracter√≠sticas tiempo-frecuencia usando transformadas wavelet.

**Qu√© hace**:
- Aplica **Transformada Wavelet Continua (CWT)** con wavelet Morlet compleja
- Aplica **Transformada Wavelet Discreta (DWT)** con wavelet Daubechies 4
- Extrae caracter√≠sticas por canal:
  - Energ√≠a en bandas alfa y beta
  - Frecuencia dominante
  - Entrop√≠a espectral
  - Estad√≠sticas de coeficientes DWT
- Genera un descriptor de 9 dimensiones por canal

**Salidas** (en `data/bof_features/` y `results/wavelets/`):
- `X_bof_features.npy`: Matriz de caracter√≠sticas (880 ensayos √ó 64 canales √ó 9 descriptores)
- `y_labels.npy`: Etiquetas de clase (0=left, 1=right)
- `trial_to_subject.npy`: Mapeo de ensayos a sujetos
- `bof_metadata.json`: Metadatos del dataset

**Tiempo estimado**: 15-30 minutos

### 3. Clasificaci√≥n BoF-SVM - `03_BoF_Clasificacion.ipynb`

**Objetivo**: Implementar y optimizar el modelo Bag of Features + SVM.

**Qu√© hace**:
- Redimensiona los datos a formato BoF: (ensayos, canales, descriptores)
- Construye un vocabulario visual mediante clustering K-means (MiniBatchKMeans)
- Codifica cada ensayo en un histograma de "palabras visuales"
- Realiza **Grid Search** para optimizar hiperpar√°metros:
  - N√∫mero de clusters K: {50, 100, 150}
  - Par√°metro de regularizaci√≥n SVM C: {1.0, 10.0, 50.0}
- Eval√∫a mediante **Validaci√≥n Cruzada por Grupos (GroupKFold)** con 5 pliegues
- Genera matriz de confusi√≥n y m√©tricas de evaluaci√≥n

**Salidas** (en `results/bof_svm/`):
- `best_params.json`: Mejores hiperpar√°metros encontrados
- `grid_search_results.csv`: Resultados de todas las combinaciones
- `confusion_matrix.npy`: Matriz de confusi√≥n final
- `summary.txt`: Resumen de resultados

**Tiempo estimado**: 10-20 minutos

### 4. DeepConvNet (CNN) - `04_DeepConvNet_CNN.ipynb`

**Objetivo**: Implementar y entrenar una arquitectura CNN profunda para clasificaci√≥n.

**Qu√© hace**:
- Implementa arquitectura DeepConvNet adaptada de Schirrmeister et al. (2017)
- Arquitectura: 4 bloques convolucionales + capas totalmente conectadas
- Divide datos: 80% entrenamiento, 10% validaci√≥n, 10% prueba
- Entrena con optimizador Adam, Early Stopping
- Eval√∫a con m√©tricas de clasificaci√≥n

**Salidas** (en `results/deepconvnet/`):
- `deepconvnet_baseline.pth`: Modelo entrenado guardado
- `metrics.npy`: M√©tricas de evaluaci√≥n
- `summary.txt`: Resumen de resultados

**Tiempo estimado**: 30-60 minutos (depende del hardware)

## üìä Resultados

### Comparaci√≥n de Modelos

| Modelo | Accuracy | Precision | Recall | F1-Score |
|--------|----------|-----------|--------|----------|
| BoF-SVM (K=50, C=10.0) | 52.84% | 52.37% | 57.12% | 0.5451 |
| **DeepConvNet** | **67.42%** | **67.42%** | **67.42%** | **0.6742** |

### Visualizaciones Disponibles

Las gr√°ficas generadas est√°n en `results/figures/`:
- `confusion_matrix_bof_svm.pdf`: Matriz de confusi√≥n del modelo BoF-SVM
- `metrics_comparison.pdf`: Comparaci√≥n de m√©tricas entre ambos modelos
- `grid_search_heatmap.pdf`: Resultados del grid search de hiperpar√°metros

### Art√≠culo Cient√≠fico

El art√≠culo completo en LaTeX est√° disponible en `articulo.md`, incluyendo:
- Revisi√≥n de literatura
- Metodolog√≠a detallada
- Resultados y an√°lisis comparativo
- Discusi√≥n y conclusiones

## üîß Configuraci√≥n y Par√°metros

### Par√°metros Principales del An√°lisis

- **Filtrado de frecuencia**: 8-30 Hz (bandas Œº y Œ≤)
- **Banda Œº**: 10-12 Hz
- **Banda Œ≤**: 18-26 Hz
- **Duraci√≥n de trial**: 9 segundos
- **Canales EEG**: 64 (est√°ndar 10-20)
- **Sujetos**: 20 (S001-S020)
- **Ensayos totales**: 880 (44 por sujeto, balanceado)

### Par√°metros del Modelo BoF-SVM

- **Clusters K**: 50 (√≥ptimo encontrado por grid search)
- **SVM C**: 10.0 (√≥ptimo encontrado por grid search)
- **Kernel SVM**: RBF (radial)
- **Validaci√≥n**: GroupKFold con 5 pliegues
- **Semilla aleatoria**: 42 (reproducibilidad)

### Par√°metros del Modelo DeepConvNet

- **Arquitectura**: 4 bloques convolucionales
- **Tasa de aprendizaje**: 0.001
- **Batch size**: 16
- **√âpocas m√°ximas**: 100 (con Early Stopping)
- **Divisi√≥n de datos**: 80/10/10 (train/val/test)

## üì¶ Dependencias Principales

El proyecto utiliza las siguientes librer√≠as (especificadas en `pyproject.toml`):

- **Procesamiento de se√±ales**: `mne>=1.10.0`, `scipy>=1.16.0`
- **Wavelets**: `PyWavelets>=1.9.0`
- **Machine Learning**: `scikit-learn>=1.7.0`
- **Deep Learning**: `torch>=2.2.0` (para DeepConvNet)
- **An√°lisis de datos**: `numpy>=1.26.0`, `pandas>=2.3.0`
- **Visualizaci√≥n**: `matplotlib>=3.10.0`, `seaborn>=0.13.0`
- **Utilidades**: `tqdm>=4.67.0`, `joblib>=1.5.0` (barras de progreso)
- **Jupyter**: `jupyter>=1.1.0`, `ipykernel>=6.0.0`

**Nota**: Todas las dependencias est√°n definidas en `pyproject.toml`. Se recomienda usar `pip install -e .` para instalar todas las dependencias de forma autom√°tica.

## ‚ùì Preguntas Frecuentes

### ¬øPuedo ejecutar los notebooks en cualquier orden?

**No**. Los notebooks tienen dependencias:
1. `01_EDA_Analysis.ipynb` debe ejecutarse primero
2. `02_Wavelet_Analysis.ipynb` depende de los datos generados por el EDA
3. `03_BoF_Clasificacion.ipynb` depende de las caracter√≠sticas wavelet
4. `04_DeepConvNet_CNN.ipynb` puede ejecutarse independientemente (usa datos preprocesados)

### ¬øQu√© pasa si ya existen archivos de salida?

Los notebooks sobrescriben los archivos de salida. Si quieres conservar resultados anteriores, haz una copia antes de ejecutar.

### ¬øCu√°nto tiempo toma ejecutar todo el pipeline?

- EDA: ~5-10 minutos
- Wavelets: ~15-30 minutos
- BoF-SVM: ~10-20 minutos
- DeepConvNet: ~30-60 minutos

**Total estimado**: 1-2 horas (depende del hardware)

### ¬øNecesito GPU para ejecutar DeepConvNet?

No es estrictamente necesario, pero acelerar√° el entrenamiento significativamente. El modelo puede entrenarse en CPU, pero tomar√° m√°s tiempo.

### ¬øC√≥mo interpreto los resultados?

- **Accuracy > 50%**: Mejor que el azar (clasificaci√≥n binaria)
- **F1-Score**: Equilibrio entre precisi√≥n y recall
- **GroupKFold**: Eval√∫a generalizaci√≥n a nuevos sujetos (m√°s conservador que validaci√≥n est√°ndar)

## üìù Notas Adicionales

- Los datos est√°n en formato **EEGLAB** (.set/.fdt)
- Todos los procesos utilizan **semilla aleatoria fija (42)** para reproducibilidad
- Los resultados se guardan en formato NumPy, CSV, JSON y PNG/PDF
- El proyecto est√° optimizado para validaci√≥n **inter-sujeto** (m√°s realista para BCI)

## üìÑ Licencia y Referencias

Este proyecto es parte de un estudio comparativo entre m√©todos cl√°sicos y de deep learning para clasificaci√≥n de se√±ales EEG. Para m√°s detalles, consulta el art√≠culo en `articulo.md`.

### Referencias Principales

- Schirrmeister, R. T., et al. (2017). Deep learning with convolutional neural networks for EEG decoding and visualization. *Human Brain Mapping*, 38(11), 5391-5420.
- Asghar, M. A., et al. (2019). EEG-Based Multi-Modal Emotion Recognition using Bag of Deep Features. *Sensors*, 19(23), 5218.

## ü§ù Contribuciones

Este es un proyecto de investigaci√≥n acad√©mica. Para preguntas o sugerencias, consulta el art√≠culo o la documentaci√≥n en los notebooks.

---

**√öltima actualizaci√≥n**: Noviembre 2024  
**Estado del proyecto**: ‚úÖ Completado - Todos los an√°lisis implementados y resultados disponibles